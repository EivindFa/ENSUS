{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import scipy\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input,Flatten, Embedding, Reshape, Multiply, Dropout, Dense, Concatenate, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Layer, SpatialDropout1D, GlobalMaxPooling1D, Bidirectional, GRU\n",
    "from tensorflow.keras.layers import Dot, TimeDistributed, BatchNormalization, multiply\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#import keras.backend as K\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle\n",
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/addressa/\"\n",
    "with open(PATH + \"articles.bin\", \"rb\") as f_in:\n",
    "    articles = pickle.load(f_in)\n",
    "# two different files: behaviors.bin and behaviors_two_days.bin\n",
    "with open(PATH + \"behaviors_7_days.bin\", \"rb\") as f_in:\n",
    "    full_behaviors = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ada20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB! REMOVE THIS (CAN STILL SHUFFLE IT THOUGH)\n",
    "full_behaviors= full_behaviors.sort_values(by=[\"user\"])\n",
    "#behaviors = behaviors.sample(frac=1).reset_index(drop=True)[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_behaviors = full_behaviors[:150000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2cc7c",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7625c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_behaviors[\"time\"] = pd.to_datetime(full_behaviors[\"time\"], unit=\"s\")\n",
    "full_behaviors.drop(columns=[\"articleId\"], inplace=True)\n",
    "full_behaviors = full_behaviors.drop_duplicates([\"user\", \"id\"])\n",
    "print(\"before merge: \",len(full_behaviors))\n",
    "full_behaviors = full_behaviors.drop(columns=[\"title\", \"author\"])\n",
    "articles.rename(columns={\"article_id\": \"id\"}, inplace=True)\n",
    "full_behaviors = full_behaviors.merge(articles, on=[\"id\"])\n",
    "print(\"after merge:\",len(full_behaviors))\n",
    "\n",
    "print(\"Len before removal: \",len(full_behaviors))\n",
    "behaviors = full_behaviors[full_behaviors.groupby('user').user.transform('count')>2].copy()\n",
    "print(\"Len after removal: \",len(behaviors))\n",
    "\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "article_enc = LabelEncoder()\n",
    "behaviors[\"user_id\"] = user_enc.fit_transform(behaviors[\"user\"].values)\n",
    "behaviors[\"article_id\"] = article_enc.fit_transform(behaviors[\"id\"].values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c03d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d01415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Helper functions\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"norwegian\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def text_to_list(text):\n",
    "    text = text.split(\" \")\n",
    "    return text\n",
    "\n",
    "def take_one_category(text):\n",
    "    temp = text.split()\n",
    "    if len(temp) > 1:\n",
    "        return temp[1]\n",
    "    return temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(df):\n",
    "    df[\"title_cleaned\"] = df.title.apply(func = make_lower_case)\n",
    "    df[\"title_cleaned\"] = df.title_cleaned.apply(func = remove_stop_words)\n",
    "    df[\"title_cleaned\"] = df.title_cleaned.apply(func = remove_punctuation)\n",
    "    return df\n",
    "def hyphen_to_underline(category):\n",
    "    \"\"\"\n",
    "    Convert hyphen to underline for the subcategories. So that Tfidf works correctly\n",
    "    \"\"\"\n",
    "    return category.replace(\"-\",\"_\")\n",
    "behaviors = clean_title(behaviors)\n",
    "behaviors[\"category_cleaned\"] = behaviors[\"kw_category\"].apply(func = take_one_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2311eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_enc = LabelEncoder()\n",
    "subcategory_enc = LabelEncoder()\n",
    "behaviors[\"category_int\"] = subcategory_enc.fit_transform(behaviors[\"category_cleaned\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(behaviors[\"category_int\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(behaviors[\"user\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e303b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(behaviors[\"article_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.histplot(behaviors[\"article_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = behaviors[\"user_id\"].unique()\n",
    "userid_to_profile = collections.defaultdict(list)\n",
    "for user_id in tqdm(users):\n",
    "    user_subcat = behaviors[behaviors[\"user_id\"] == user_id][\"category_int\"].values.tolist()\n",
    "    counter = Counter(user_subcat)\n",
    "    s = sorted(user_subcat, key=lambda x: (counter[x], x), reverse=True)\n",
    "    final_subcategories = []\n",
    "    for elem in s:\n",
    "        if elem not in final_subcategories:\n",
    "            final_subcategories.append(elem)\n",
    "    while len(final_subcategories) < 6:\n",
    "        final_subcategories.append(0)\n",
    "    userid_to_profile[user_id] = final_subcategories[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae089c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a80d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = pd.DataFrame.from_dict(userid_to_profile, orient=\"index\")\n",
    "profile_df[\"user_id\"] = profile_df.index\n",
    "behaviors = behaviors.merge(profile_df, on=\"user_id\")\n",
    "behaviors = behaviors.rename(columns={\"0\": \"p0\",\"1\": \"p1\",\"2\": \"p2\",\"3\": \"p3\",\"4\": \"p4\",\"5\": \"p5\",})\n",
    "\n",
    "article_id_to_category_int = behaviors[[\"article_id\", \"category_int\"]].set_index(\"article_id\").to_dict()\n",
    "article_id_to_category_int = article_id_to_category_int[\"category_int\"]\n",
    "\n",
    "behaviors.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc36b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#behaviors.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d015fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#behaviors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad190c",
   "metadata": {},
   "source": [
    "# 2. Train test spliit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors[\"rank_latest\"] = behaviors.groupby([\"user_id\"])[\"time\"].rank(method=\"first\", ascending=False)\n",
    "\n",
    "train_true = behaviors[behaviors['rank_latest'] != 1]\n",
    "test_true = behaviors[behaviors['rank_latest'] == 1]\n",
    "\n",
    "rating = [1 for i in range(len(train_true))]\n",
    "train_true = train_true.assign(e=pd.Series(rating))\n",
    "#train_true.loc[-1,\"label\"] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14471aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_userid_to_article_history(df):\n",
    "    userid_to_article_history = {}\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()):\n",
    "        click_history = df[df[\"user_id\"] == user_id][\"article_id\"].values\n",
    "        if len(click_history) < 10:\n",
    "            while len(click_history) < 10:\n",
    "                click_history = np.append(click_history, 0)\n",
    "        if len(click_history) > 10:\n",
    "            click_history = click_history[:10]\n",
    "        userid_to_article_history[user_id] = click_history\n",
    "    return userid_to_article_history\n",
    "userid_to_article_history = get_userid_to_article_history(train_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(userid_to_article_history))\n",
    "print(len(behaviors[\"user_id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_article_ids = behaviors[\"article_id\"].unique()\n",
    "\n",
    "def negative_sampling(train_df, all_article_ids, user_id, article_id):\n",
    "    \"\"\"\n",
    "    Negative sample training instance; for each positive instance, add 4 negative articles\n",
    "    \n",
    "    Return user_ids, news_ids, category_1, category_2, authors_onehotencoded, titles\n",
    "    \"\"\"\n",
    "    \n",
    "    user_ids, user_click_history, articles, article_category, labels = [], [], [], [], []\n",
    "    p0, p1, p2, p3, p4, p5, p6, p7, p8, p9 = [], [], [], [], [], [], [], [], [], []\n",
    "    user_item_set = set(zip(train_df[user_id], \n",
    "                            train_df[article_id]))\n",
    "    num_negatives = 4\n",
    "\n",
    "    for (u, i) in tqdm(user_item_set):\n",
    "        user_ids.append(u)\n",
    "        user_click_history.append(userid_to_article_history[u])\n",
    "        profile = np.array(userid_to_profile[u])\n",
    "        p0.append(profile[0])\n",
    "        p1.append(profile[1])\n",
    "        p2.append(profile[2])\n",
    "        p3.append(profile[3])\n",
    "        p4.append(profile[4])\n",
    "        p5.append(profile[5])\n",
    "        article_category.append(article_id_to_category_int[i])\n",
    "        \n",
    "        \n",
    "        for _ in range(num_negatives):\n",
    "            negative_item = np.random.choice(all_article_ids)\n",
    "            while (u, negative_item) in user_item_set:\n",
    "                negative_item = np.random.choice(all_article_ids)\n",
    "            user_ids.append(u)\n",
    "            user_click_history.append(userid_to_article_history[u])\n",
    "            p0.append(profile[0])\n",
    "            p1.append(profile[1])\n",
    "            p2.append(profile[2])\n",
    "            p3.append(profile[3])\n",
    "            p4.append(profile[4])\n",
    "            p5.append(profile[5])\n",
    "            \n",
    "            article_category.append(article_id_to_category_int[negative_item])\n",
    "            \n",
    "            articles.append(negative_item)\n",
    "            labels.append(0)\n",
    "        articles.append(i)\n",
    "        labels.append(1)\n",
    "    \n",
    "    user_ids, user_click_history, p0, p1, p2, p3, p4, p5, articles,article_category, labels = shuffle(user_ids,user_click_history, p0, p1, p2, p3, p4, p5, articles,article_category, labels, random_state=0)\n",
    "\n",
    "    return pd.DataFrame(list(zip(user_ids,user_click_history,p0, p1, p2, p3, p4, p5, articles,article_category, labels)), columns=[\"user_id\",\"user_history\",\"p0\", \"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"article_id\",\"article_category\", \"labels\"])\n",
    "\n",
    "\n",
    "\n",
    "df_train = negative_sampling(train_true, all_article_ids, \"user_id\", \"article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dftrain(df, column, max_len, padding):\n",
    "    i = 0\n",
    "    for i in tqdm(range(max_len)):\n",
    "        df[column + \"_\" + str(i)] = df[column].apply(lambda x: x[i] if i < len(x) else padding)\n",
    "    #df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train = fix_dftrain(df_train, \"user_history\", 10, 0)\n",
    "df_train.drop(columns=[\"user_history\"], inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f681562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[df_train[\"user_id\"]==1752]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20dc3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each user; for each item the user has interacted with in the test set;\n",
    "    # Sample 99 items the user has not interacted with in the past and add the one test item  \n",
    "    \n",
    "def negative_sample_testset(ordiginal_df, df_test, all_article_ids, user_id, article_id):\n",
    "    test_user_item_set = set(zip(df_test[user_id], df_test[article_id]))\n",
    "    user_interacted_items = ordiginal_df.groupby(user_id)[article_id].apply(list).to_dict()\n",
    "    users = []\n",
    "    p0, p1, p2, p3, p4, p5, p6, p7, p8, p9 = [], [], [], [], [], [], [], [], [], []\n",
    "    res_arr = []\n",
    "    article_category, article_sub_category = [], []\n",
    "    \n",
    "    userid_to_true_item = {} # keep track of the real items\n",
    "    for (u,i) in tqdm(test_user_item_set):\n",
    "        interacted_items = user_interacted_items[u]\n",
    "        not_interacted_items = set(all_article_ids) - set(interacted_items)\n",
    "        selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "        test_items =[i] + selected_not_interacted \n",
    "        temp = []\n",
    "        profile = userid_to_profile[u]\n",
    "        for j in range(len(test_items)):\n",
    "            temp.append([u,\n",
    "                         userid_to_article_history[u], \n",
    "                         profile[0],\n",
    "                         profile[1],\n",
    "                         profile[2],\n",
    "                         profile[3],\n",
    "                         profile[4],\n",
    "                         profile[5], \n",
    "                         test_items[j], article_id_to_category_int[test_items[j]]])\n",
    "        #            user_click_history.append(userid_to_article_history[u])\n",
    "\n",
    "        res_arr.append(temp)\n",
    "        userid_to_true_item[u] = i \n",
    "    X_test = np.array(res_arr)\n",
    "    X_test = X_test.reshape(-1, X_test.shape[-1])\n",
    "    df_test = pd.DataFrame(X_test, columns=[\"user_id\",\n",
    "                                            \"click_history\", \n",
    "                                            \"p0\", \n",
    "                                            \"p1\", \n",
    "                                            \"p2\", \n",
    "                                            \"p3\", \n",
    "                                            \"p4\", \n",
    "                                            \"p5\",\n",
    "                                            \"article_id\", \n",
    "                                            \"category\"])\n",
    "    return X_test, df_test, userid_to_true_item\n",
    "X_test, df_test, userid_to_true_item = negative_sample_testset(behaviors, test_true, behaviors[\"article_id\"].unique(), \"user_id\", \"article_id\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40748038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[df_test[\"user_id\"] == 4744]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dftest(df, column, max_len, padding):\n",
    "    i = 0\n",
    "    for i in tqdm(range(max_len)):\n",
    "        df[column + \"_\" + str(i)] = df[column].apply(lambda x: x[i] if i < len(x) else padding)\n",
    "    #df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_test = fix_dftest(df_test, \"click_history\", 10, 0)\n",
    "df_test.drop(columns=[\"click_history\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61bc19",
   "metadata": {},
   "source": [
    "# 4. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feaac7c",
   "metadata": {},
   "source": [
    "# 4.1 NeuMF - without features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c15244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_one_rating_neumf(model, user_id, all_articles, true_item):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    predictions = model.predict([expanded_user_id, all_articles])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    print(predicted_labels)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg, hr_five, ndcg_five\n",
    "\n",
    "def evalaute_model_neumf(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()[:400]\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].to_numpy().astype(int) # get all possible articles\n",
    "        \n",
    "        ht, ndcg, ht_five, ndcg_five = evaluate_one_rating_neumf(model, user_id, all_articles, true_item)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(ht_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs, hits_five, ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637da54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(behaviors[\"user_id\"].unique())\n",
    "num_items = len(behaviors[\"article_id\"].unique())\n",
    "dims = 20\n",
    "def get_model_neumf(num_users, num_items, dims, dense_layers=[128, 64, 32, 8]):\n",
    "    user_input = Input(shape=(1,), name=\"user\")\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    \n",
    "    mf_user_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_users, \n",
    "                            input_length=1, \n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            name=\"mf_user_emb\")(user_input)\n",
    "    mf_item_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_items, \n",
    "                            input_length=1, \n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            name=\"mf_item_emb\")(item_input)\n",
    "    \n",
    "    num_layers = len(dense_layers)\n",
    "    mlp_user_emb = Embedding(output_dim=int(dense_layers[0] / 2), \n",
    "                             input_dim=num_users, \n",
    "                             input_length=1, \n",
    "                             embeddings_initializer='he_normal', \n",
    "                             embeddings_regularizer=regularizers.l2(0.001),\n",
    "                             name=\"mlp_user_emb\")(user_input)\n",
    "    mlp_item_emb = Embedding(output_dim=int(dense_layers[0] / 2), \n",
    "                             input_dim=num_items, \n",
    "                             input_length=1, \n",
    "                             embeddings_initializer='he_normal', \n",
    "                             embeddings_regularizer=regularizers.l2(0.001),\n",
    "                             name=\"mlp_user_item\")(item_input)\n",
    "    \n",
    "    # Matrix factorization\n",
    "    mf_user_vecs = Reshape([dims])(mf_user_emb)\n",
    "    mf_item_vecs = Reshape([dims])(mf_item_emb)\n",
    "    \n",
    "    mf_vec = multiply([mf_user_vecs, mf_item_vecs])\n",
    "    \n",
    "    #MLP\n",
    "    mlp_vec = Concatenate()([mlp_user_emb, mlp_item_emb])\n",
    "    mlp_vector = Flatten()(mlp_vec)\n",
    "    \n",
    "    for num_nodes in dense_layers:\n",
    "        l = Dense(num_nodes, activation=\"relu\")\n",
    "        mlp_vector = l(mlp_vector)\n",
    "    \n",
    "    y = Concatenate()([mf_vec, mlp_vector])\n",
    "    y = Dense(1, activation=\"sigmoid\", name=\"pred\")(y)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_input, item_input], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_neumf = get_model_neumf(num_users, num_items, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1,1))\n",
    "print(user_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3422563",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = df_train[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    hist = model_neumf.fit([user_input, item_input], labels, epochs=1, shuffle=True, verbose=1, validation_split=0.1, batch_size=512)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    #hits, ndcgs, hits_five, ndcgs_five = evalaute_model_neumf( model_neumf, df_test, userid_to_true_item)\n",
    "    #hits_list.append(np.average(hits))\n",
    "    #ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    #temp_hits = np.average(hits)\n",
    "    #temp_ndcgs = np.average(ndcgs)\n",
    "    #if (temp_hits > best_hits):\n",
    "    #    best_hits = temp_hits\n",
    "    #    best_ndcgs = temp_ndcgs\n",
    "    #    best_hits_five = np.average(hits_five)\n",
    "    #    best_ndcgs_five = np.average(ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hit @ 10: {:.2f}\".format(best_hits))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(best_ndcgs))\n",
    "print(\"Hit @ 10: {:.2f}\".format(best_hits_five))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(best_ndcgs_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, ndcgs, hits_five, ndcgs_five = evalaute_model_neumf( model_neumf, df_test, userid_to_true_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca740baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"final_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce3c52",
   "metadata": {},
   "source": [
    "# 4.2 Popularity based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ea592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_df = pd.DataFrame(behaviors[\"article_id\"].value_counts())\n",
    "most_popular_df = most_popular_df.reset_index()\n",
    "most_popular_df.columns=[\"article_id\", \"counts\"]\n",
    "most_popular_articles = most_popular_df[\"article_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_recommender(top_n, user_interactions, most_popular_articles,num_unique_users):\n",
    "    \"\"\"\n",
    "    params: \n",
    "        top_n: number of articles to recommend\n",
    "    \"\"\"\n",
    "    all_article_ids = behaviors[\"article_id\"].unique()\n",
    "    recommendations = {}\n",
    "    for (u,i) in tqdm(user_interactions.items()):\n",
    "        interacted_items = user_interactions[u]\n",
    "        popular_items_not_interacted_with = []\n",
    "        for i in range(10):\n",
    "            counter = i\n",
    "            popular_item = most_popular_articles[i]\n",
    "            while popular_item in interacted_items:\n",
    "                counter += 1\n",
    "                popular_item = most_popular_articles[counter]\n",
    "            popular_items_not_interacted_with.append(popular_item)\n",
    "        recommendations[u] = list(popular_items_not_interacted_with)\n",
    "    return recommendations\n",
    "\n",
    "user_interactions = df_train.groupby(\"user_id\")[\"article_id\"].apply(list).to_dict()\n",
    "num_unique_users = len(df_train[\"user_id\"].unique())\n",
    "recs = popularity_recommender(10, user_interactions, most_popular_articles, num_unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df_test[\"user_id\"].unique()[:400]\n",
    "hit_ten = 0\n",
    "hit_five = 0\n",
    "for user_id in tqdm(users):\n",
    "    user_df = df_test[df_test[\"user_id\"]==user_id]\n",
    "    true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "    recommendations = recs[user_id]\n",
    "    five_recommendations = recommendations[:5]\n",
    "    if true_item in recommendations:\n",
    "        hit_ten+=1\n",
    "    if true_item in five_recommendations:\n",
    "        hit_five += 1\n",
    "print(hit_ten/len(users))\n",
    "print(hit_five / len(users))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb9dda",
   "metadata": {},
   "source": [
    "# 4.3 Wide and deep - with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_wide(model, user_id, user_profiles, all_articles,categories, true_item):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    predictions = model.predict([expanded_user_id, user_profiles, all_articles,categories])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    #print(predicted_labels)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg, hr_five, ndcg_five\n",
    "\n",
    "def evalaute_model_wide(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()[:400]\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].to_numpy().astype(int) # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].to_numpy().astype(int)# get the user_profile\n",
    "        \n",
    "        categories = user_df.iloc[:, 8].to_numpy().astype(int)\n",
    "        \n",
    "        ht, ndcg, ht_five, ndcg_five = evaluate_one_rating_wide(model, user_id, user_profiles, all_articles,categories, true_item)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(ht_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs,hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0fab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(behaviors[\"user_id\"].unique()) \n",
    "num_items = len(behaviors[\"article_id\"].unique()) \n",
    "num_categories = len(behaviors[\"category_int\"].unique()) \n",
    "dims = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_wide(num_users, num_items, dims, dense_layers=[128, 64, 32, 8]):\n",
    "    #### Matrix factorization ####\n",
    "    user_id_input = Input(shape=[1], name=\"user_id\")\n",
    "    item_id_input = Input(shape=[1], name=\"item_id\")\n",
    "    user_embedding = Embedding(input_dim=num_users, \n",
    "                               output_dim=dims, \n",
    "                               input_length=1, \n",
    "                               embeddings_initializer='he_normal', \n",
    "                               embeddings_regularizer=regularizers.l2(0.001),\n",
    "                               name=\"user_embedding\")(user_id_input)\n",
    "    item_embedding = Embedding(input_dim=num_items, \n",
    "                               output_dim=dims, \n",
    "                               embeddings_initializer='he_normal', \n",
    "                               embeddings_regularizer=regularizers.l2(0.001),\n",
    "                               name=\"item_embedding\")(item_id_input)\n",
    "    \n",
    "    user_flatten = Flatten()(user_embedding)\n",
    "    item_flatten = Flatten()(item_embedding)\n",
    "    mf_vec = Concatenate()([user_flatten, item_flatten])\n",
    "    \n",
    "    x_deep = Dense(128, activation=\"relu\", kernel_initializer='he_uniform',kernel_regularizer=regularizers.l2(0.001))(mf_vec)\n",
    "    x_deep = Dropout(0.2)(x_deep)\n",
    "    x_deep = Dense(64, activation=\"relu\",\n",
    "                   kernel_initializer='he_uniform', \n",
    "                   kernel_regularizer=regularizers.l2(0.001))(x_deep)\n",
    "    x_deep = Dropout(0.2)(x_deep)\n",
    "    \n",
    "    #### Wide part ####\n",
    "    \n",
    "    user_profile_input = Input(shape=(6,), name=\"user_profile\")\n",
    "    item_category_input = Input(shape=(1,), name=\"category_input\")\n",
    "    \n",
    "    item_category_emb = Embedding(input_dim=num_categories, output_dim=dims, name=\"category_emd\", embeddings_regularizer=regularizers.l2(0.001))(item_category_input)\n",
    "    user_profile_emb = Embedding(input_dim=num_categories, output_dim=dims,\n",
    "                                 embeddings_regularizer=regularizers.l2(0.001), name=\"profile_emb\")(user_profile_input)\n",
    "\n",
    "    item_category_flatten = Flatten()(item_category_emb)\n",
    "    user_profile_flatten = Flatten()(user_profile_emb)\n",
    "    \n",
    "    wide_features = Concatenate()([item_category_flatten,  user_profile_flatten])\n",
    "    \n",
    "    x_wide = Dense(128, activation=\"relu\",kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.001))(wide_features)\n",
    "    x_wide = Dropout(0.5)(x_wide)\n",
    "    x_wide = Dense(64, activation=\"relu\",kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.001))(x_wide)\n",
    "    x_wide = Dropout(0.5)(x_wide)\n",
    "    \n",
    "    final = Concatenate()([x_deep,x_wide])\n",
    "    x = Dense(128, kernel_initializer='he_uniform',activation=\"relu\")(final)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_id_input, user_profile_input, item_id_input, item_category_input], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_wide = get_model_wide(num_users, num_items, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17253e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "profile_input = df_train.iloc[:, 1:7].values\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1))\n",
    "category_input = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "print(user_input.shape,profile_input.shape, item_input.shape,category_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = df_train[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "\n",
    "\n",
    "epochs=25\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hist = model_wide.fit([user_input, profile_input, item_input,category_input], labels,validation_split=0.1, epochs=1, shuffle=True, verbose=1, batch_size=32)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    #hits, ndcgs, hits_five, ndcgs_five = evalaute_model_wide( model_wide, df_test, userid_to_true_item)\n",
    "    #hits_list.append(np.average(hits))\n",
    "    #ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    #temp_hits = np.average(hits)\n",
    "    #temp_ndcgs = np.average(ndcgs)\n",
    "    #if (temp_hits > best_hits):\n",
    "    #    best_hits = temp_hits\n",
    "    #    best_hits_five = np.average(hits_five)\n",
    "    #    best_ndcgs_five = np.average(ndcgs_five)\n",
    "    #    best_ndcgs = temp_ndcgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_hits)\n",
    "print(best_ndcgs)\n",
    "print(best_hits_five)\n",
    "print(best_ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a0b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, ndcgs, hits_five, ndcgs_five = evalaute_model_wide( model_wide, df_test, userid_to_true_item)\n",
    "print(np.average(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e214ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"final_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf7f77f",
   "metadata": {},
   "source": [
    "# 4.4 NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904738a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_ncf(model, user_id, all_articles, true_item):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    predictions = model.predict([expanded_user_id, all_articles])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg,hr_five,ndcg_five\n",
    "\n",
    "def evalaute_model_ncf(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()[:400]\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].to_numpy().astype(int) # get all possible articles\n",
    "        \n",
    "        ht, ndcg, ht_five, ndcg_five = evaluate_one_rating_ncf(model, user_id, all_articles, true_item)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(ht_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs,hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_ncf(num_users, num_items, dims, dense_layers=[128, 64, 32, 8]):\n",
    "    user_input = Input(shape=(1,), name=\"user\")\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    \n",
    "    user_emb = Embedding(output_dim=dims, \n",
    "                         input_dim=num_users, \n",
    "                         input_length=1, \n",
    "                         embeddings_initializer='he_normal', \n",
    "                         embeddings_regularizer=regularizers.l2(0.001),\n",
    "                         name=\"mf_user_emb\")(user_input)\n",
    "    item_emb = Embedding(output_dim=dims, \n",
    "                         input_dim=num_items, \n",
    "                         input_length=1, \n",
    "                         embeddings_initializer='he_normal', \n",
    "                         embeddings_regularizer=regularizers.l2(0.001),\n",
    "                         name=\"mf_item_emb\")(item_input)\n",
    "    \n",
    "    user_vecs = Reshape([dims])(user_emb)\n",
    "    item_vecs = Reshape([dims])(item_emb)\n",
    "    \n",
    "    y = Dot(1, normalize=False)([user_vecs, item_vecs])\n",
    "    \n",
    "    y = Dense(1, activation=\"sigmoid\")(y)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_input, item_input], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_ncf = get_model_ncf(num_users, num_items, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682516a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1,1))\n",
    "print(user_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c87c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_user_ids = df_train[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "    hist = model_ncf.fit([user_input, item_input], labels, epochs=1, shuffle=True, verbose=1, validation_split=0.1)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    hits, ndcgs, ht_five, ndcg_five = evalaute_model_ncf( model_ncf, df_test, userid_to_true_item)\n",
    "    hits_list.append(np.average(hits))\n",
    "    ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    temp_hits = np.average(hits)\n",
    "    temp_ndcgs = np.average(ndcgs)\n",
    "    if (temp_hits > best_hits):\n",
    "        best_hits = temp_hits\n",
    "        best_hits_five = np.average(ht_five)\n",
    "        best_ndcgs_five = np.average(ndcg_five)\n",
    "        best_ndcgs = temp_ndcgs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_hits)\n",
    "print(best_ndcgs)\n",
    "print(best_hits_five)\n",
    "print(best_ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7836c8f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-19dd5f9846cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"darkgrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"final_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34207c8d",
   "metadata": {},
   "source": [
    "# 4.5 NeuMF with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_neumffeat(model, user_id, user_profiles, all_articles,categories, true_item):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    predictions = model.predict([expanded_user_id, user_profiles, all_articles,categories])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    #print(predicted_labels)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg, hr_five, ndcg_five\n",
    "\n",
    "def evalaute_model_neumffeat(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()[:400]\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].to_numpy().astype(int) # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].to_numpy().astype(int)# get the user_profile\n",
    "        \n",
    "        categories = user_df.iloc[:, 8].to_numpy().astype(int)\n",
    "        \n",
    "        ht, ndcg, ht_five, ndcg_five = evaluate_one_rating_neumffeat(model, user_id, user_profiles, all_articles,categories, true_item)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(ht_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs,hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65f7741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_neumffeat(num_users, num_items, dims, dense_layers=[128, 64, 32, 8]):\n",
    "    user_input = Input(shape=(1,), name=\"user\")\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    \n",
    "    mf_user_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_users, \n",
    "                            input_length=1, \n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            name=\"mf_user_emb\")(user_input)\n",
    "    mf_item_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_items, \n",
    "                            input_length=1, \n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            name=\"mf_item_emb\")(item_input)\n",
    "    \n",
    "    num_layers = len(dense_layers)\n",
    "    mlp_user_emb = Embedding(output_dim=int(dense_layers[0] / 2), \n",
    "                             input_dim=num_users, \n",
    "                             input_length=1, \n",
    "                             embeddings_initializer='he_normal', \n",
    "                             embeddings_regularizer=regularizers.l2(0.001),\n",
    "                             name=\"mlp_user_emb\")(user_input)\n",
    "    mlp_item_emb = Embedding(output_dim=int(dense_layers[0] / 2), \n",
    "                             input_dim=num_items, \n",
    "                             input_length=1, \n",
    "                             embeddings_initializer='he_normal', \n",
    "                             embeddings_regularizer=regularizers.l2(0.001),\n",
    "                             name=\"mlp_user_item\")(item_input)\n",
    "    \n",
    "    # Matrix factorization\n",
    "    mf_user_vecs = Reshape([dims])(mf_user_emb)\n",
    "    mf_item_vecs = Reshape([dims])(mf_item_emb)\n",
    "    \n",
    "    mf_vec = multiply([mf_user_vecs, mf_item_vecs])\n",
    "    \n",
    "    #MLP\n",
    "    profile_input = Input(shape=(6,), name=\"user_profile\")\n",
    "    category_input = Input(shape=(1,), name=\"category_input\")\n",
    "    sub_category_input = Input(shape=(1,), name=\"subcategory_input\")\n",
    "    \n",
    "    item_category_emb = Embedding(input_dim=num_categories, \n",
    "                                  output_dim=int(dense_layers[0] / 2), \n",
    "                                  name=\"category_emd\", \n",
    "                                  embeddings_regularizer=regularizers.l2(0.001))(category_input)\n",
    "    user_profile_emb = Embedding(input_dim=num_categories, \n",
    "                                 output_dim=int(dense_layers[0] / 2),\n",
    "                                 embeddings_regularizer=regularizers.l2(0.001), \n",
    "                                 name=\"profile_emb\")(profile_input)\n",
    "\n",
    "    item_category_flatten = Flatten()(item_category_emb)\n",
    "    user_profile_flatten = Flatten()(user_profile_emb)\n",
    "    \n",
    "    wide_features = Concatenate()([item_category_flatten,  user_profile_flatten])\n",
    "    mlp_vector = Flatten()(wide_features)\n",
    "    for num_dense in dense_layers:\n",
    "        l = Dense(num_dense, activation=\"relu\")\n",
    "        mlp_vector = l(mlp_vector)\n",
    "        mlp_vector = Dropout(0.2)(mlp_vector)\n",
    "    \n",
    "\n",
    "    \n",
    "    mlp_vec = Concatenate()([mlp_user_emb, mlp_item_emb])\n",
    "    mlp_vector = Flatten()(mlp_vec)\n",
    "    \n",
    "    y = Concatenate()([mf_vec, mlp_vector])\n",
    "    y = Dense(1, activation=\"sigmoid\", name=\"pred\")(y)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_input, profile_input, item_input,category_input], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_neumffeat = get_model_neumffeat(num_users, num_items, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d62819",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "profile_input = df_train.iloc[:, 1:7].values\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1))\n",
    "category_input = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "print(user_input.shape,profile_input.shape, item_input.shape,category_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fcf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = df_train[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "\n",
    "\n",
    "epochs=2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hist = model_neumffeat.fit([user_input, profile_input, item_input,category_input], labels,validation_split=0.1, epochs=1, shuffle=True, verbose=1)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    hits, ndcgs, hits_five, ndcgs_five = evalaute_model_neumffeat( model_neumffeat, df_test, userid_to_true_item)\n",
    "    hits_list.append(np.average(hits))\n",
    "    ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    temp_hits = np.average(hits)\n",
    "    temp_ndcgs = np.average(ndcgs)\n",
    "    if (temp_hits > best_hits):\n",
    "        best_hits = temp_hits\n",
    "        best_hits_five = np.average(hits_five)\n",
    "        best_ndcgs_five = np.average(ndcgs_five)\n",
    "        best_ndcgs = temp_ndcgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_hits)\n",
    "print(best_ndcgs)\n",
    "print(best_hits_five)\n",
    "print(best_ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"final_loss.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
