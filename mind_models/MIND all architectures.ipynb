{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46db04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import scipy\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input,Flatten, Embedding, Reshape, Multiply, Dropout, Dense, Concatenate, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Layer, SpatialDropout1D, GlobalMaxPooling1D, Bidirectional, GRU, LSTM\n",
    "from tensorflow.keras.layers import Dot, TimeDistributed, BatchNormalization, Add, Multiply\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#import keras.backend as K\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import math\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cbdab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c3eccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/mind_small/\"\n",
    "news = pd.read_csv(PATH + \"news.tsv\",header=None, sep=\"\\t\")\n",
    "behaviors = pd.read_csv(PATH + \"behaviors.tsv\", header=None, sep=\"\\t\")\n",
    "news.columns = [\"news_id\", \"category\", \"sub_category\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    "behaviors.columns = [\"idx\", \"user_id\", \"time\", \"history\", \"impressions\"]\n",
    "behaviors = behaviors.drop_duplicates([\"user_id\", \"history\"]) \n",
    "behaviors.dropna(subset=[\"user_id\", \"history\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1d0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = {}\n",
    "for idx, row in behaviors.iterrows():\n",
    "    sessions[row[\"user_id\"]] = row[\"history\"].split(\" \")\n",
    "\n",
    "users = []\n",
    "clicks = []\n",
    "for k, v in sessions.items():\n",
    "    for elem in v:\n",
    "        users.append(k)\n",
    "        clicks.append(elem)\n",
    "\n",
    "tuples = list(zip(users, clicks))\n",
    "interactions = pd.DataFrame(tuples, columns=[\"user\", \"news_id\"])\n",
    "interactions = interactions[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c90b524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U13740</td>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>We'd like to solve the puzzle, Pat: Blair Davi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAIORni.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U10045</td>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>We'd like to solve the puzzle, Pat: Blair Davi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAIORni.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U85394</td>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>We'd like to solve the puzzle, Pat: Blair Davi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAIORni.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U78244</td>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>We'd like to solve the puzzle, Pat: Blair Davi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAIORni.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U27024</td>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>We'd like to solve the puzzle, Pat: Blair Davi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAIORni.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user news_id category sub_category  \\\n",
       "0  U13740  N55189       tv       tvnews   \n",
       "1  U10045  N55189       tv       tvnews   \n",
       "2  U85394  N55189       tv       tvnews   \n",
       "3  U78244  N55189       tv       tvnews   \n",
       "4  U27024  N55189       tv       tvnews   \n",
       "\n",
       "                                               title  \\\n",
       "0  'Wheel Of Fortune' Guest Delivers Hilarious, O...   \n",
       "1  'Wheel Of Fortune' Guest Delivers Hilarious, O...   \n",
       "2  'Wheel Of Fortune' Guest Delivers Hilarious, O...   \n",
       "3  'Wheel Of Fortune' Guest Delivers Hilarious, O...   \n",
       "4  'Wheel Of Fortune' Guest Delivers Hilarious, O...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  We'd like to solve the puzzle, Pat: Blair Davi...   \n",
       "1  We'd like to solve the puzzle, Pat: Blair Davi...   \n",
       "2  We'd like to solve the puzzle, Pat: Blair Davi...   \n",
       "3  We'd like to solve the puzzle, Pat: Blair Davi...   \n",
       "4  We'd like to solve the puzzle, Pat: Blair Davi...   \n",
       "\n",
       "                                             url title_entities  \\\n",
       "0  https://assets.msn.com/labs/mind/AAIORni.html             []   \n",
       "1  https://assets.msn.com/labs/mind/AAIORni.html             []   \n",
       "2  https://assets.msn.com/labs/mind/AAIORni.html             []   \n",
       "3  https://assets.msn.com/labs/mind/AAIORni.html             []   \n",
       "4  https://assets.msn.com/labs/mind/AAIORni.html             []   \n",
       "\n",
       "                                   abstract_entities  \n",
       "0  [{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...  \n",
       "1  [{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...  \n",
       "2  [{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...  \n",
       "3  [{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...  \n",
       "4  [{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = interactions.merge(news, on=[\"news_id\"])\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba44358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "9861\n"
     ]
    }
   ],
   "source": [
    "print(len(merged))\n",
    "merged = merged.drop_duplicates()\n",
    "print(len(merged))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4790cb",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a73e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len before removal:  9861\n",
      "Len after removal:  9728\n"
     ]
    }
   ],
   "source": [
    "# remove users which have fewer than 5 interacations\n",
    "print(\"Len before removal: \",len(merged))\n",
    "_keys = merged[\"user\"].value_counts()[merged[\"user\"].value_counts() > 5].keys()\n",
    "merged = merged[merged[\"user\"].isin(_keys)]\n",
    "print(\"Len after removal: \",len(merged))\n",
    "\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "article_enc = LabelEncoder()\n",
    "merged[\"user_id\"] = user_enc.fit_transform(merged[\"user\"].values)\n",
    "merged[\"article_id\"] = article_enc.fit_transform(merged[\"news_id\"].values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e215d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Helper functions\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def text_to_list(text):\n",
    "    text = text.split(\" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e8a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(df):\n",
    "    df[\"title_cleaned\"] = df.title.apply(func = make_lower_case)\n",
    "    df[\"title_cleaned\"] = df.title_cleaned.apply(func = remove_stop_words)\n",
    "    df[\"title_cleaned\"] = df.title_cleaned.apply(func = remove_punctuation)\n",
    "    return df\n",
    "def hyphen_to_underline(category):\n",
    "    \"\"\"\n",
    "    Convert hyphen to underline for the subcategories. So that Tfidf works correctly\n",
    "    \"\"\"\n",
    "    return category.replace(\"-\",\"_\")\n",
    "merged = clean_title(merged)\n",
    "merged[\"subcategory_cleaned\"] = merged[\"sub_category\"].apply(func = hyphen_to_underline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19630bd2",
   "metadata": {},
   "source": [
    "# Alternative to tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfda724",
   "metadata": {},
   "source": [
    "# End alternative to tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a25b007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9728x164 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9728 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=\"word\", tokenizer=str.split)\n",
    "item_ids = merged[\"article_id\"].unique().tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(merged[\"subcategory_cleaned\"])\n",
    "tfidf_feature_names = vectorizer.get_feature_names()\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2526c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids = merged[\"article_id\"].tolist()\n",
    "\n",
    "def get_item_profile(item_id):\n",
    "    \"\"\"\n",
    "    item_id: the news article id\n",
    "    Return: an array of each n-gram in the item article. \n",
    "        with their n-gram id in tfidf_feature_names and weight.\n",
    "    \"\"\"\n",
    "    idx = item_ids.index(item_id) # returns the index to the item id\n",
    "    item_profile = tfidf_matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "    \n",
    "def get_item_profiles(ids):\n",
    "    #print(ids)\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_user_profile(person_id):\n",
    "    interactions = merged[merged[\"user_id\"] == person_id][\"article_id\"].values # gets all articles\n",
    "    user_item_profiles = get_item_profiles(interactions)\n",
    "    user_item_profiles = np.sum(user_item_profiles, axis=0)\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(user_item_profiles)\n",
    "    return user_item_profiles\n",
    "    \n",
    "#t = build_user_profile(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a46e1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [00:07<00:00, 29.50it/s]\n"
     ]
    }
   ],
   "source": [
    "def calculate_user_profiles(unique_user_ids):\n",
    "    user_profiles = {}\n",
    "    for idx in tqdm(unique_user_ids):\n",
    "        token_relevance = build_user_profile(idx).tolist()[0]\n",
    "        zipped = zip(tfidf_feature_names, token_relevance)\n",
    "        s = sorted(zipped, key=lambda x: -x[-1])[:6]\n",
    "        user_profiles[idx] = s\n",
    "    return user_profiles\n",
    "        \n",
    "user_profiles = calculate_user_profiles(merged[\"user_id\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cac49a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategory_to_id = {name: idx+1 for idx, name in enumerate(tfidf_feature_names)}\n",
    "id_to_subcategory = {idx: name for name, idx in subcategory_to_id.items()}\n",
    "id_to_subcategory[0] = \"Null\"\n",
    "subcategory_to_id[\"Null\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9430a76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9728it [00:00, 11841.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# add all id-category to the userprofile in df\n",
    "profile_array = []\n",
    "for index, row in tqdm(merged.iterrows()):\n",
    "    \n",
    "    user_idx = row[\"user_id\"]\n",
    "    profile = user_profiles[user_idx]\n",
    "    temp = []\n",
    "    for keyword_tuple in profile:\n",
    "        temp.append(subcategory_to_id[keyword_tuple[0]])\n",
    "    profile_array.append(temp)\n",
    "merged[\"profile\"] = profile_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb68db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the id-category to the news articles\n",
    "merged[\"subcategory_to_int\"] = [subcategory_to_id[cat] for cat in merged[\"subcategory_cleaned\"].values]\n",
    "\n",
    "user_unique = merged.drop_duplicates(\"user_id\")\n",
    "userid_to_profile = user_unique[[\"user_id\", \"profile\"]].set_index(\"user_id\").to_dict()[\"profile\"]\n",
    "\n",
    "category_enc = LabelEncoder()\n",
    "merged[\"main_category_int\"] = category_enc.fit_transform(merged[\"category\"].values)\n",
    "article_id_to_category_int = merged[[\"article_id\", \"main_category_int\"]].set_index(\"article_id\").to_dict()\n",
    "article_id_to_category_int = article_id_to_category_int[\"main_category_int\"]\n",
    "\n",
    "article_id_to_subcategory_int = merged[[\"article_id\", \"subcategory_to_int\"]].set_index(\"article_id\").to_dict()\n",
    "article_id_to_subcategory_int = article_id_to_subcategory_int[\"subcategory_to_int\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db9701ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, user_id, article_id, have_timestamp, timestamp):\n",
    "    \"\"\"\n",
    "    params: \n",
    "        col_1: user_id\n",
    "        col_2: article_id\n",
    "    \"\"\"\n",
    "    df_test = df\n",
    "    if have_timestamp: # if df have timestamp; take last interacted article into test set\n",
    "        df_test = df_test.sort_values(timestamp).groupby(user_id).tail(1)\n",
    "    else:\n",
    "        df_test = df_test.sort_values(user_id).groupby(user_id).tail(1)\n",
    "    df_train = df.drop(index=df_test.index)\n",
    "    \n",
    "    assert df_test.shape[0] + df_train.shape[0] == df.shape[0]\n",
    "    \n",
    "    return df_train, df_test\n",
    "df_train_true, df_test_true = train_test_split(merged, \"user_id\", \"article_id\", False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fdcef1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>subcategory_cleaned</th>\n",
       "      <th>profile</th>\n",
       "      <th>subcategory_to_int</th>\n",
       "      <th>main_category_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U13740</td>\n",
       "      <td>N55189</td>\n",
       "      <td>tv</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>'Wheel Of Fortune' Guest Delivers Hilarious, O...</td>\n",
       "      <td>We'd like to solve the puzzle, Pat: Blair Davi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAIORni.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...</td>\n",
       "      <td>13</td>\n",
       "      <td>3563</td>\n",
       "      <td>wheel fortune guest delivers hilarious rails i...</td>\n",
       "      <td>tvnews</td>\n",
       "      <td>[119, 151, 23, 61, 74, 99]</td>\n",
       "      <td>151</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user news_id category sub_category  \\\n",
       "0  U13740  N55189       tv       tvnews   \n",
       "\n",
       "                                               title  \\\n",
       "0  'Wheel Of Fortune' Guest Delivers Hilarious, O...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  We'd like to solve the puzzle, Pat: Blair Davi...   \n",
       "\n",
       "                                             url title_entities  \\\n",
       "0  https://assets.msn.com/labs/mind/AAIORni.html             []   \n",
       "\n",
       "                                   abstract_entities  user_id  article_id  \\\n",
       "0  [{\"Label\": \"Pat Sajak\", \"Type\": \"P\", \"Wikidata...       13        3563   \n",
       "\n",
       "                                       title_cleaned subcategory_cleaned  \\\n",
       "0  wheel fortune guest delivers hilarious rails i...              tvnews   \n",
       "\n",
       "                      profile  subcategory_to_int  main_category_int  \n",
       "0  [119, 151, 23, 61, 74, 99]                 151                 11  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_true.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dadc61f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [00:00<00:00, 1400.28it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_userid_to_article_history(df):\n",
    "    userid_to_article_history = {}\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()):\n",
    "        click_history = df[df[\"user_id\"] == user_id][\"article_id\"].values\n",
    "        if len(click_history) < 30:\n",
    "            while len(click_history) < 30:\n",
    "                click_history = np.append(click_history, 0)\n",
    "        if len(click_history) > 30:\n",
    "            click_history = click_history[:30]\n",
    "        userid_to_article_history[user_id] = click_history\n",
    "    return userid_to_article_history\n",
    "userid_to_article_history = get_userid_to_article_history(df_train_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04703f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_article_ids = merged[\"article_id\"].unique()\n",
    "\n",
    "def negative_sampling(train_df, all_article_ids, user_id, article_id):\n",
    "    \"\"\"\n",
    "    Negative sample training instance; for each positive instance, add 4 negative articles\n",
    "    \n",
    "    Return user_ids, news_ids, category_1, category_2, authors_onehotencoded, titles\n",
    "    \"\"\"\n",
    "    \n",
    "    user_ids, user_click_history, articles, article_category, article_sub_category, labels = [], [], [], [], [], []\n",
    "    p0, p1, p2, p3, p4, p5, p6, p7, p8, p9 = [], [], [], [], [], [], [], [], [], []\n",
    "    user_item_set = set(zip(train_df[user_id], \n",
    "                            train_df[article_id]))\n",
    "    num_negatives = 4\n",
    "\n",
    "    for (u, i) in tqdm(user_item_set):\n",
    "        user_ids.append(u)\n",
    "        user_click_history.append(userid_to_article_history[u])\n",
    "        profile = np.array(userid_to_profile[u])\n",
    "        p0.append(profile[0])\n",
    "        p1.append(profile[1])\n",
    "        p2.append(profile[2])\n",
    "        p3.append(profile[3])\n",
    "        p4.append(profile[4])\n",
    "        p5.append(profile[5])\n",
    "        article_category.append(article_id_to_category_int[i])\n",
    "        article_sub_category.append(article_id_to_subcategory_int[i])\n",
    "        \n",
    "        articles.append(i)\n",
    "        labels.append(1)\n",
    "        for _ in range(num_negatives):\n",
    "            negative_item = np.random.choice(all_article_ids)\n",
    "            while (u, negative_item) in user_item_set:\n",
    "                negative_item = np.random.choice(all_article_ids)\n",
    "            user_ids.append(u)\n",
    "            user_click_history.append(userid_to_article_history[u])\n",
    "            p0.append(profile[0])\n",
    "            p1.append(profile[1])\n",
    "            p2.append(profile[2])\n",
    "            p3.append(profile[3])\n",
    "            p4.append(profile[4])\n",
    "            p5.append(profile[5])\n",
    "            \n",
    "            article_category.append(article_id_to_category_int[negative_item])\n",
    "            article_sub_category.append(article_id_to_subcategory_int[negative_item])\n",
    "            \n",
    "            articles.append(negative_item)\n",
    "            labels.append(0)\n",
    "    \n",
    "    user_ids, user_click_history, p0, p1, p2, p3, p4, p5, articles,article_category,article_sub_category, labels = shuffle(user_ids,user_click_history, p0, p1, p2, p3, p4, p5, articles,article_category,article_sub_category, labels, random_state=0)\n",
    "\n",
    "    return pd.DataFrame(list(zip(user_ids,user_click_history,p0, p1, p2, p3, p4, p5, articles,article_category,article_sub_category, labels)), columns=[\"user_id\",\"user_history\",\"p0\", \"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"article_id\",\"article_category\",\"article_sub_category\", \"labels\"])\n",
    "\n",
    "\n",
    "\n",
    "df_train = negative_sampling(df_train_true, all_article_ids, \"user_id\", \"article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dftrain(df, column, max_len, padding):\n",
    "    i = 0\n",
    "    for i in tqdm(range(max_len)):\n",
    "        df[column + \"_\" + str(i)] = df[column].apply(lambda x: x[i] if i < len(x) else padding)\n",
    "    #df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train = fix_dftrain(df_train, \"user_history\", 30, 0)\n",
    "df_train.drop(columns=[\"user_history\"], inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada88639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each user; for each item the user has interacted with in the test set;\n",
    "    # Sample 99 items the user has not interacted with in the past and add the one test item  \n",
    "    \n",
    "def negative_sample_testset(ordiginal_df, df_test, all_article_ids, user_id, article_id):\n",
    "    test_user_item_set = set(zip(df_test[user_id], df_test[article_id]))\n",
    "    user_interacted_items = ordiginal_df.groupby(user_id)[article_id].apply(list).to_dict()\n",
    "    users = []\n",
    "    p0, p1, p2, p3, p4, p5, p6, p7, p8, p9 = [], [], [], [], [], [], [], [], [], []\n",
    "    res_arr = []\n",
    "    article_category, article_sub_category = [], []\n",
    "    \n",
    "    userid_to_true_item = {} # keep track of the real items\n",
    "    for (u,i) in tqdm(test_user_item_set):\n",
    "        interacted_items = user_interacted_items[u]\n",
    "        not_interacted_items = set(all_article_ids) - set(interacted_items)\n",
    "        selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "        test_items = selected_not_interacted + [i]\n",
    "        temp = []\n",
    "        profile = userid_to_profile[u]\n",
    "        for j in range(len(test_items)):\n",
    "            temp.append([u,\n",
    "                         userid_to_article_history[u], \n",
    "                         profile[0],\n",
    "                         profile[1],\n",
    "                         profile[2],\n",
    "                         profile[3],\n",
    "                         profile[4],\n",
    "                         profile[5], \n",
    "                         test_items[j], article_id_to_category_int[test_items[j]],\n",
    "                        article_id_to_subcategory_int[test_items[j]]])\n",
    "        #            user_click_history.append(userid_to_article_history[u])\n",
    "\n",
    "        res_arr.append(temp)\n",
    "        userid_to_true_item[u] = i \n",
    "    X_test = np.array(res_arr)\n",
    "    X_test = X_test.reshape(-1, X_test.shape[-1])\n",
    "    df_test = pd.DataFrame(X_test, columns=[\"user_id\",\n",
    "                                            \"click_history\", \n",
    "                                            \"p0\", \n",
    "                                            \"p1\", \n",
    "                                            \"p2\", \n",
    "                                            \"p3\", \n",
    "                                            \"p4\", \n",
    "                                            \"p5\",\n",
    "                                            \"article_id\", \n",
    "                                            \"category\", \n",
    "                                            \"sub_category\"])\n",
    "    return X_test, df_test, userid_to_true_item\n",
    "X_test, df_test, userid_to_true_item = negative_sample_testset(merged, df_test_true, merged[\"article_id\"].unique(), \"user_id\", \"article_id\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6235ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dftest(df, column, max_len, padding):\n",
    "    i = 0\n",
    "    for i in tqdm(range(max_len)):\n",
    "        df[column + \"_\" + str(i)] = df[column].apply(lambda x: x[i] if i < len(x) else padding)\n",
    "    #df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_test = fix_dftest(df_test, \"click_history\", 30, 0)\n",
    "df_test.drop(columns=[\"click_history\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c080b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0\n",
    "\n",
    "def getNumHits(ranklist, gtItem):\n",
    "    h = 0\n",
    "    for item in ranklist:\n",
    "        for p in gtItem:\n",
    "            if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating(model, user_id, user_profiles, all_articles,user_clicks, true_item, categories, sub_categories):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    #expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    #user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    predictions = model.predict([user_clicks, user_profiles, all_articles, categories, sub_categories]) #TODO: add categories, sub_cat\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg,hr_five,ndcg_five\n",
    "\n",
    "def evalaute_model(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five = []\n",
    "    ndcgs_five = []\n",
    "    users = df_test[\"user_id\"].unique()\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].values.astype(\"int64\")# get the user_profile\n",
    "        user_clicks = user_df.iloc[:, 10:].values.astype(\"int64\")\n",
    "        categories = user_df.iloc[:, 8].values.astype(\"int64\")\n",
    "        sub_categories = user_df.iloc[:, 9].values.astype(\"int64\")\n",
    "        \n",
    "        ht, ndcg, ht_five, ndcg_five = evaluate_one_rating(model, \n",
    "                                       user_id, \n",
    "                                       user_profiles, \n",
    "                                       all_articles,user_clicks, \n",
    "                                       true_item, \n",
    "                                       categories, \n",
    "                                       sub_categories)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(ht_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs,hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_accuracy_results(model_name, hit_ten, ndcg_ten, hit_five, ndcg_five):\n",
    "    try:\n",
    "        file = open(\"performance.txt\", \"a\")\n",
    "        s = model_name +\": Hit@10 : \"+ str(hit_ten)+\", NDCG@10: \"+ str(ndcg_ten)+\", Hit@5:\" + str(hit_five)+\", ndcg@5 \"+ str(ndcg_five) + \"\\n\"\n",
    "        file.write(s)\n",
    "        file.close()\n",
    "    except:\n",
    "        print(\"error file wriite\")\n",
    "\n",
    "def write_category_results(model_name, hit_ten, ndcg_ten, hit_five, ndcg_five):\n",
    "    try:\n",
    "        file = open(\"category_performance.txt\", \"a\")\n",
    "    \n",
    "        s = model_name +\": Hit@10 : \"+ str(hit_ten)+\", NDCG@10: \"+ str(ndcg_ten)+\", Hit@5:\" + str(hit_five)+\", ndcg@5 \"+ str(ndcg_five) + \"\\n\"\n",
    "        file.write(s)\n",
    "        file.close()\n",
    "    except:\n",
    "        print(\"error file wriite\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dddc2e",
   "metadata": {},
   "source": [
    "# 4. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca6099",
   "metadata": {},
   "source": [
    "## 4.1 Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "num_unique_categories = len(subcategory_to_id)\n",
    "num_users = len(merged[\"user_id\"].unique()) +1\n",
    "num_items = len(merged[\"article_id\"].unique()) + 1\n",
    "dims = 20\n",
    "num_sub_categories = len(merged[\"subcategory_to_int\"].unique()) +1\n",
    "num_categories = len(merged[\"main_category_int\"].unique()) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "def get_model(num_users, num_items, dims,num_categories,num_sub_categories, dense_layers=[128, 64, 32, 8]):\n",
    "    #User features\n",
    "    user_history = Input(shape=(30,), name=\"user\")\n",
    "    user_profile_input = Input(shape=(6,), name=\"profile\")\n",
    "    #item features\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    item_category = Input(shape=(1,), name=\"category\")\n",
    "    item_subcategory = Input(shape=(1,), name=\"subcategory\")\n",
    "    \n",
    "    # User emb\n",
    "    click_history_emb = Embedding(output_dim=dims, input_dim=num_items+1, input_length=30, name=\"mf_user_emb\")(user_history)\n",
    "    profile_emb = Embedding(output_dim=dims, input_dim=num_unique_categories, input_length=6, name=\"mf_profile_emb\")(user_profile_input)\n",
    "    \n",
    "    # Item emb\n",
    "    item_emb = Embedding(output_dim=dims, input_dim=num_items+1, input_length=1, name=\"mf_item_emb\")(item_input)\n",
    "    category_emb = Embedding(output_dim=dims, input_dim=num_categories, input_length=1, name=\"cat_emb\")(item_category)\n",
    "    subcategory_emb = Embedding(output_dim=dims, input_dim=num_sub_categories, input_length=1, name=\"subcat_emb\")(item_subcategory)\n",
    "    \n",
    "    ### Wide\n",
    "    #wide_history = Flatten()(click_history_emb)\n",
    "    #wide_item = Flatten()(item_input)\n",
    "    wide = Concatenate(axis=1)([click_history_emb, item_emb])\n",
    "    wide = Flatten()(wide)\n",
    "    y_wide = Dense(2)(wide)\n",
    "    \n",
    "    ### Deep\n",
    "    deep_features = Concatenate(axis=1)([category_emb,subcategory_emb, profile_emb])\n",
    "    x_deep = LSTM(40)(deep_features)\n",
    "    \n",
    "    print(x_deep.shape)\n",
    "    print(y_wide.shape)\n",
    "    \n",
    "    final = Concatenate()([x_deep, y_wide])\n",
    "    final = BatchNormalization(axis=1)(final)\n",
    "   \n",
    "    y = Dense(1, activation=\"sigmoid\")(final)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_history, user_profile_input, item_input, item_category, item_subcategory], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = get_model(num_users, num_items, dims, num_categories,num_sub_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_history = df_train.iloc[:, 11:].values.astype(\"int64\")\n",
    "profile_input = df_train.iloc[:, 1:7].values.astype(\"int64\")\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1)).astype(\"int64\")\n",
    "labels = df_train.iloc[:, 10].values.reshape((-1,1)).astype(\"int64\")\n",
    "category_input = df_train.iloc[:, 8].values.reshape((-1,1)).astype(\"int64\")\n",
    "subcategory_input = df_train.iloc[:, 9].values.reshape((-1,1)).astype(\"int64\")\n",
    "print(user_history.shape,profile_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef30ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = merged[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=2\n",
    "for epoch in range(epochs):\n",
    "    hist = model.fit([user_history, profile_input, item_input,category_input, subcategory_input ], labels, epochs=1,validation_split=0.1, shuffle=True, verbose=1)    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    hits, ndcgs, hits_five, ndcgs_five = evalaute_model( model, df_test, userid_to_true_item)\n",
    "    hits_list.append(np.average(hits))\n",
    "    ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    temp_hits = np.average(hits)\n",
    "    temp_ndcgs = np.average(ndcgs)\n",
    "    if (temp_hits > best_hits):\n",
    "        best_hits = temp_hits\n",
    "        best_ndcgs = temp_ndcgs\n",
    "        best_hits_five = np.average(hits_five)\n",
    "        best_ndcgs_five = np.average(ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hit @ 10: {:.2f}\".format(best_hits))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(best_ndcgs))\n",
    "print(\"Hit @ 10: {:.2f}\".format(best_hits_five))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(best_ndcgs_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_accuracy_results(\"main\", best_hits, best_ndcgs, best_hits_five, best_ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"final_accuracy.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3563609",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"final_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d5f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(hits_list)\n",
    "plt.plot(train_loss)\n",
    "plt.title('Hit ratio vs Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Hit@10', 'Train loss'], loc='upper left')\n",
    "plt.savefig(\"final_hit_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144815d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ceec5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518a01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e998b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_category(article_id):\n",
    "    return merged[merged[\"article_id\"] == article_id][\"subcategory_cleaned\"].values[0]\n",
    "def get_userprofile_to_name(user_id, id_to_subcategory):\n",
    "    \"\"\"\n",
    "    Return array of strings with category names\n",
    "    \"\"\"\n",
    "    arr_profile = get_user_profile(df_train,user_id )\n",
    "    return [id_to_subcategory[elem] for elem in arr_profile]\n",
    "def get_user_profile(df, user_id):\n",
    "    \"\"\"\n",
    "    Return the user profile given user_id\n",
    "    \"\"\"\n",
    "    return df[df[\"user_id\"] == user_id].iloc[0, 1:7].values\n",
    "def get_article_content(article_id):\n",
    "    article = merged[merged[\"article_id\"] == article_id].head(1)\n",
    "    title = article[\"title\"].values[0]\n",
    "    sub_category = article[\"sub_category\"].values[0]\n",
    "    return title, sub_category\n",
    "\n",
    "def get_item_features(user_id):\n",
    "    d = df_test[df_test[\"user_id\"] == user_id]\n",
    "    return d[\"category\"].values.reshape(-1,1), d[\"sub_category\"].values.reshape(-1,1)\n",
    "\n",
    "def get_item_features_one_item(article_id):\n",
    "    d = df_test[df_test[\"article_id\"] == article_id]\n",
    "    return np.array(d[\"category\"].values[0]), np.array(d[\"sub_category\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_category(article_id, df):\n",
    "    \"\"\"\n",
    "    Return the article's category\n",
    "        type: int\n",
    "    \"\"\"\n",
    "    return df[df[\"article_id\"] == article_id][\"category\"].values[0]\n",
    "def get_article_subcategory(article_id, df):\n",
    "    \"\"\"\n",
    "    Return the article's category\n",
    "        type: int\n",
    "    \"\"\"\n",
    "    return df[df[\"article_id\"] == article_id][\"sub_category\"].values[0]\n",
    "def get_category_hit_ratio(user_profile, top_ten_categories):\n",
    "    for profile in user_profile:\n",
    "        for category in top_ten_categories:\n",
    "            if profile == category:\n",
    "                return 1\n",
    "    return 0\n",
    "def get_ndcgs_category(user_profile, top_ten_categories):\n",
    "    for i in range(len(top_ten_categories)):\n",
    "        item = top_ten_categories[i]\n",
    "        for profile in user_profile:\n",
    "            if item == profile:\n",
    "                return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id, df):\n",
    "    \n",
    "    ## Setup ###\n",
    "    user_profile = get_user_profile(df, user_id)\n",
    "    click_history = userid_to_article_history[user_id]\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_profile = np.tile(user_profile, display_items.shape[0]).reshape(-1, 6).astype(\"int64\")\n",
    "    category, sub_category = get_item_features(user_id)\n",
    "    user_ids = np.tile(np.array(user_id), display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    category = np.asarray(category).astype(\"int64\")\n",
    "    sub_category = np.asarray(sub_category).astype(\"int64\")\n",
    "    click_history = np.tile(click_history, display_items.shape[0]).reshape(-1, 30).astype(\"int64\")\n",
    "\n",
    "    ## Preds ###\n",
    "    predictions = model.predict([click_history, user_profile, display_items, category, sub_category])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8075a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_users(df):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "\n",
    "    counter = 0\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()):\n",
    "        top_ten_articles = get_recommendations(user_id, df)\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = get_user_profile(df_test, user_id)\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        counter += 1\n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten,category_hits_five,category_ndcg_five   = predict_all_users(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_category_results(\"main\", category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c15f4",
   "metadata": {},
   "source": [
    "# 4.1 Architecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15507033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_arc1(model, user_id, all_articles, true_item):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    predictions = model.predict([expanded_user_id, all_articles])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg, hr_five, ndcg_five\n",
    "\n",
    "def evalaute_model_arc1(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        \n",
    "        \n",
    "        ht, ndcg, hr_five, ndcg_five = evaluate_one_rating_arc1(model, user_id, all_articles, true_item)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(hr_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs, hits_five, ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ac38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "num_users = len(merged[\"user_id\"].unique())\n",
    "num_items = len(merged[\"article_id\"].unique()) \n",
    "dims = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "def get_model(num_users, num_items, dims, dense_layers=[128, 64, 32, 8]):\n",
    "    user_input = Input(shape=(1,), name=\"user\")\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    \n",
    "    user_emb = Embedding(output_dim=dims, input_dim=num_users, input_length=1, name=\"mf_user_emb\")(user_input)\n",
    "    item_emb = Embedding(output_dim=dims, input_dim=num_items, input_length=1, name=\"mf_item_emb\")(item_input)\n",
    "    \n",
    "    user_vecs = Reshape([dims])(user_emb)\n",
    "    item_vecs = Reshape([dims])(item_emb)\n",
    "    \n",
    "    y = Dot(1, normalize=False)([user_vecs, item_vecs])\n",
    "    \n",
    "    y = Dense(1, activation=\"sigmoid\")(y)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_input, item_input], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_arc1 = get_model(num_users, num_items, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b63dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "labels = df_train.iloc[:, 10].values.reshape((-1,1))\n",
    "print(user_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066bad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = df_train[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "\n",
    "epochs=2\n",
    "for epoch in range(epochs):\n",
    "    hist = model_arc1.fit([user_input, item_input], labels, epochs=1, shuffle=True, verbose=1, validation_split=0.1)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc1( model_arc1, df_test, userid_to_true_item)\n",
    "    hits_list.append(np.average(hits))\n",
    "    ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    temp_hits = np.average(hits)\n",
    "    temp_ndcgs = np.average(ndcgs)\n",
    "    if (temp_hits > best_hits):\n",
    "        best_hits = temp_hits\n",
    "        best_ndcgs = temp_ndcgs\n",
    "        best_hits_five = np.average(hits_five)\n",
    "        best_ndcgs_five = np.average(ndcgs_five)\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0573d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_hits)\n",
    "print(best_ndcgs)\n",
    "print(best_hits_five)\n",
    "print(best_ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_accuracy_results(\"arc1\", best_hits, best_ndcgs, best_hits_five, best_ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc1_accuracy.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc1_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(hits_list)\n",
    "plt.plot(train_loss)\n",
    "plt.title('Hit ratio vs Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Hit@10', 'Train loss'], loc='upper left')\n",
    "plt.savefig(\"arc1_hit_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de715ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796c024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92742d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_arc1(user_id, df, model):\n",
    "    \n",
    "    ## Setup ###\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_ids = np.tile(np.array(user_id), display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    \n",
    "    ## Preds ###\n",
    "    predictions = model.predict([user_ids, display_items])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_hits_ndcg_arc1(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    \n",
    "    for user_id in tqdm(df[\"user_id\"].unique()):\n",
    "        top_ten_articles = get_recommendations_arc1(user_id, df, model)\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = userid_to_profile[user_id]\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        \n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        \n",
    "        \n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five = get_category_hits_ndcg_arc1(df_test,model_arc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3bf643",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce734ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_category_results(\"arc1\", category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a90654",
   "metadata": {},
   "source": [
    "# 4.3 Architecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9e1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_arc2(model, user_id, user_profiles, all_articles,user_clicks, true_item):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    #expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    predictions = model.predict([user_clicks, user_profiles, all_articles])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg, hr_five,ndcg_five\n",
    "\n",
    "def evalaute_model_arc2(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].values.astype(\"int64\")# get the user_profile\n",
    "        user_clicks = user_df.iloc[:, 10:].values.astype(\"int64\")\n",
    "        \n",
    "        ht, ndcg,hr_five,ndcg_five = evaluate_one_rating_arc2(model, user_id, user_profiles, all_articles,user_clicks, true_item)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(hr_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs,hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "def get_model_arc2(num_users, num_items, dims, dense_layers=[128, 64, 32, 8]):\n",
    "    user_history = Input(shape=(30,), name=\"user\")\n",
    "    user_profile_input = Input(shape=(6,), name=\"profile\")\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    \n",
    "    mf_user_emb = Embedding(output_dim=dims, input_dim=num_items+1, input_length=30, name=\"mf_user_emb\")(user_history)\n",
    "    mf_profile_emb = Embedding(output_dim=dims, input_dim=num_unique_categories, input_length=6, name=\"mf_profile_emb\")(user_profile_input)\n",
    "    mf_item_emb = Embedding(output_dim=dims, input_dim=num_items+1, input_length=1, name=\"mf_item_emb\")(item_input)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #profile_emb = GlobalAveragePooling1D()(mf_profile_emb)\n",
    "    profile_vecs = Flatten()(mf_user_emb)\n",
    "    user_vecs = Flatten()(mf_profile_emb)\n",
    "    item_vecs = Reshape([dims])(mf_item_emb)\n",
    "    \n",
    "    user_vecs_complete = Concatenate(axis=1)([user_vecs, profile_vecs])\n",
    "    input_vecs = Concatenate()([user_vecs_complete, item_vecs])\n",
    "    x = Dense(128, activation=\"relu\", name=\"dense_0\")(input_vecs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(1, activation=\"sigmoid\", name=\"prediction\")(x)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_history, user_profile_input, item_input], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_arc2 = get_model_arc2(num_users, num_items, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23beaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bda4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_history = df_train.iloc[:, 11:].values.astype(\"int64\")\n",
    "profile_input = df_train.iloc[:, 1:7].values.astype(\"int64\")\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1)).astype(\"int64\")\n",
    "labels = df_train.iloc[:, 10].values.reshape((-1,1)).astype(\"int64\")\n",
    "print(user_history.shape,profile_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = merged[\"user_id\"].unique()\n",
    "\n",
    "epochs=2\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hist = model_arc2.fit([user_history, profile_input, item_input], labels, epochs=1, shuffle=True, verbose=1, validation_split=0.1)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc2( model_arc2, df_test, userid_to_true_item)\n",
    "    hits_list.append(np.average(hits))\n",
    "    ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    temp_hits = np.average(hits)\n",
    "    temp_ndcgs = np.average(ndcgs)\n",
    "    if (temp_hits > best_hits):\n",
    "        best_hits = temp_hits\n",
    "        best_hits_five = np.average(hits_five)\n",
    "        best_ndcgs_five = np.average(ndcgs_five)\n",
    "        best_ndcgs = temp_ndcgs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hit @ 10: {:.2f}\".format(best_hits))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(best_ndcgs))\n",
    "print(\"Hit @ 5: {:.2f}\".format(best_hits_five))\n",
    "print(\"ncdgs @ 5: {:.2f}\".format(best_ndcgs_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_accuracy_results(\"arc2\", best_hits, best_ndcgs, best_hits_five, best_ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f63d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc2_accuracy.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc2_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(hits_list)\n",
    "plt.plot(train_loss)\n",
    "plt.title('Hit ratio vs Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Hit@10', 'Train loss'], loc='upper left')\n",
    "plt.savefig(\"arc2_hit_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba23553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c5bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caafa25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_arc2(user_id, df, model):\n",
    "    #user_history, profile_input, item_input\n",
    "    ## Setup ###\n",
    "    \n",
    "    click_history = userid_to_article_history[user_id]\n",
    "    user_profile = get_user_profile(df, user_id)\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_profile = np.tile(user_profile, display_items.shape[0]).reshape(-1, 6).astype(\"int64\")\n",
    "    click_history = np.tile(np.array(click_history), display_items.shape[0]).reshape(-1,30).astype(\"int64\")\n",
    "    \n",
    "    ## Preds ###\n",
    "    predictions = model.predict([click_history, user_profile,display_items])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb76b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_hits_ndcg_arc2(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    \n",
    "    for user_id in tqdm(df[\"user_id\"].unique()):\n",
    "        top_ten_articles = get_recommendations_arc2(user_id, df, model)\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = userid_to_profile[user_id]\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        \n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        \n",
    "        \n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five = get_category_hits_ndcg_arc2(df_test, model_arc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269497dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_category_results(\"arc2\", category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19594297",
   "metadata": {},
   "source": [
    "# 4.4 Architecture 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b29ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64187ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_arc3(model, user_id, user_profiles, all_articles,user_clicks, true_item, categories, sub_categories):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    #expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    #user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    predictions = model.predict([user_clicks, user_profiles, all_articles, categories, sub_categories]) #TODO: add categories, sub_cat\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg, hr_five,ndcg_five \n",
    "\n",
    "def evalaute_model_arc3(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].values.astype(\"int64\")# get the user_profile\n",
    "        user_clicks = user_df.iloc[:, 10:].values.astype(\"int64\")\n",
    "        categories = user_df.iloc[:, 8].values.astype(\"int64\")\n",
    "        sub_categories = user_df.iloc[:, 9].values.astype(\"int64\")\n",
    "        \n",
    "        ht, ndcg, hr_five,ndcg_five = evaluate_one_rating_arc3(model, \n",
    "                                       user_id, \n",
    "                                       user_profiles, \n",
    "                                       all_articles,user_clicks, \n",
    "                                       true_item, \n",
    "                                       categories, \n",
    "                                       sub_categories)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(hr_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs, hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "def get_model_arc3(num_users, num_items, dims,num_categories,num_sub_categories, dense_layers=[128, 64, 32, 8]):\n",
    "    #User features\n",
    "    user_history = Input(shape=(30,), name=\"user\")\n",
    "    user_profile_input = Input(shape=(6,), name=\"profile\")\n",
    "    #item features\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    item_category = Input(shape=(1,), name=\"category\")\n",
    "    item_subcategory = Input(shape=(1,), name=\"subcategory\")\n",
    "    \n",
    "    # User emb\n",
    "    click_history_emb = Embedding(output_dim=dims, input_dim=num_items+1, input_length=30, name=\"mf_user_emb\")(user_history)\n",
    "    profile_emb = Embedding(output_dim=dims, input_dim=num_unique_categories, input_length=6, name=\"mf_profile_emb\")(user_profile_input)\n",
    "    \n",
    "    #user_features = Concatenate(axis=1)([click_history_emb,profile_emb])\n",
    "    \n",
    "    # Item emb\n",
    "    item_emb = Embedding(output_dim=dims, input_dim=num_items+1, input_length=1, name=\"mf_item_emb\")(item_input)\n",
    "    category_emb = Embedding(output_dim=dims, input_dim=num_categories, input_length=1, name=\"cat_emb\")(item_category)\n",
    "    subcategory_emb = Embedding(output_dim=dims, input_dim=num_sub_categories, input_length=1, name=\"subcat_emb\")(item_subcategory)\n",
    "    \n",
    "    item_features = Concatenate(axis=1)([item_emb,category_emb, subcategory_emb, profile_emb])\n",
    "    \n",
    "    # User-tower\n",
    "    user_lstm = LSTM(40)(click_history_emb)\n",
    "    user_lstm = Dropout(0.5)(user_lstm)\n",
    "    user_lstm = BatchNormalization(axis=1)(user_lstm)\n",
    "    \n",
    "    # Item tower\n",
    "    item_dense = Flatten()(item_features)\n",
    "    item_dense = Dense(128)(item_dense)\n",
    "    item_dense = Dropout(0.5)(item_dense)\n",
    "    item_dense = BatchNormalization(axis=1)(item_dense)\n",
    "    \n",
    "    # Click predictor\n",
    "    final = Concatenate()([user_lstm,item_dense ])\n",
    "    y = Dense(1, activation=\"sigmoid\")(final)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_history, user_profile_input, item_input, item_category, item_subcategory], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_arc3 = get_model_arc3(num_users, num_items, dims, num_categories,num_sub_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_history = df_train.iloc[:, 11:].values.astype(\"int64\")\n",
    "profile_input = df_train.iloc[:, 1:7].values.astype(\"int64\")\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1)).astype(\"int64\")\n",
    "labels = df_train.iloc[:, 10].values.reshape((-1,1)).astype(\"int64\")\n",
    "category_input = df_train.iloc[:, 8].values.reshape((-1,1)).astype(\"int64\")\n",
    "subcategory_input = df_train.iloc[:, 9].values.reshape((-1,1)).astype(\"int64\")\n",
    "print(user_history.shape,profile_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a8dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = merged[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=2\n",
    "for epoch in range(epochs):\n",
    "    hist = model_arc3.fit([user_history, profile_input, item_input,category_input, subcategory_input ], labels, validation_split=0.1, epochs=1, shuffle=True, verbose=1)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc3( model_arc3, df_test, userid_to_true_item)\n",
    "    hits_list.append(np.average(hits))\n",
    "    ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    temp_hits = np.average(hits)\n",
    "    temp_ndcgs = np.average(ndcgs)\n",
    "    if (temp_hits > best_hits):\n",
    "        best_hits = temp_hits\n",
    "        best_hits_five = np.average(hits_five)\n",
    "        best_ndcgs_five = np.average(ndcgs_five)\n",
    "        best_ndcgs = temp_ndcgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hit @ 10: {:.2f}\".format(best_hits))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(best_ndcgs))\n",
    "print(\"Hit @ 5: {:.2f}\".format(best_hits_five))\n",
    "print(\"ncdgs @ 5: {:.2f}\".format(best_ndcgs_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc01d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_accuracy_results(\"arc3\", best_hits, best_ndcgs, best_hits_five, best_ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765273a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc3_accuracy.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc3_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e42ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(hits_list)\n",
    "plt.plot(train_loss)\n",
    "plt.title('Hit ratio vs Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Hit@10', 'Train loss'], loc='upper left')\n",
    "plt.savefig(\"arc3_hit_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956a5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab601ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f84f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc86416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_arc3(user_id, df,model):\n",
    "    #user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    ## Setup ###\n",
    "    click_history = userid_to_article_history[user_id]\n",
    "    user_profile = get_user_profile(df, user_id)\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_profile = np.tile(user_profile, display_items.shape[0]).reshape(-1, 6).astype(\"int64\")\n",
    "    category, sub_category = get_item_features(user_id)\n",
    "    click_history = np.tile(np.array(click_history), display_items.shape[0]).reshape(-1,30).astype(\"int64\")\n",
    "    category = np.asarray(category).astype(\"int64\")\n",
    "    sub_category = np.asarray(sub_category).astype(\"int64\")\n",
    "    #category = np.tile(category, display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    #sub_category = np.tile(sub_category, display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    \n",
    "    ## Preds ###\n",
    "    predictions = model.predict([click_history, user_profile, display_items, category, sub_category])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items\n",
    "\n",
    "def predict_all_users_arc3(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    counter = 0\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()):\n",
    "        top_ten_articles = get_recommendations_arc3(user_id, df, model)\n",
    "        assert len(top_ten_articles) == 10\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = get_user_profile(df_test, user_id)\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        counter += 1\n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten,category_hits_five,category_ndcg_five   = predict_all_users_arc3(df_test, model_arc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d47b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_category_results(\"arc3\", category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab68724",
   "metadata": {},
   "source": [
    "# 4.5 Architecture 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff86b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_arc4(model, user_id, user_profiles, all_articles,user_clicks, true_item, categories, sub_categories):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    #expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    #user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    predictions = model.predict([user_clicks, user_profiles, all_articles, categories, sub_categories]) #TODO: add categories, sub_cat\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg,hr_five,ndcg_five\n",
    "\n",
    "def evalaute_model_arc4(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five = []\n",
    "    ndcgs_five = []\n",
    "    users = df_test[\"user_id\"].unique()\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].values.astype(\"int64\")# get the user_profile\n",
    "        user_clicks = user_df.iloc[:, 10:].values.astype(\"int64\")\n",
    "        categories = user_df.iloc[:, 8].values.astype(\"int64\")\n",
    "        sub_categories = user_df.iloc[:, 9].values.astype(\"int64\")\n",
    "        \n",
    "        ht, ndcg, hr_five, ndcg_five = evaluate_one_rating_arc4(model, \n",
    "                                       user_id, \n",
    "                                       user_profiles, \n",
    "                                       all_articles,user_clicks, \n",
    "                                       true_item, \n",
    "                                       categories, \n",
    "                                       sub_categories)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(hr_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs, hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "def get_model_arc4(num_users, num_items, dims,num_categories,num_sub_categories, dense_layers=[128, 64, 32, 8]):\n",
    "    #User features\n",
    "    user_history = Input(shape=(30,), name=\"user\")\n",
    "    user_profile_input = Input(shape=(6,), name=\"profile\")\n",
    "    #item features\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    item_category = Input(shape=(1,), name=\"category\")\n",
    "    item_subcategory = Input(shape=(1,), name=\"subcategory\")\n",
    "    \n",
    "    # User emb\n",
    "    click_history_emb = Embedding(output_dim=dims, input_dim=num_items+1, input_length=30, name=\"mf_user_emb\")(user_history)\n",
    "    profile_emb = Embedding(output_dim=dims, input_dim=num_unique_categories, input_length=6, name=\"mf_profile_emb\")(user_profile_input)\n",
    "    \n",
    "    # Item emb\n",
    "    item_emb = Embedding(output_dim=dims, input_dim=num_items+1, input_length=1, name=\"mf_item_emb\")(item_input)\n",
    "    category_emb = Embedding(output_dim=dims, input_dim=num_categories, input_length=1, name=\"cat_emb\")(item_category)\n",
    "    subcategory_emb = Embedding(output_dim=dims, input_dim=num_sub_categories, input_length=1, name=\"subcat_emb\")(item_subcategory)\n",
    "    \n",
    "    lstm_tower = Concatenate(axis=1)([click_history_emb,item_emb])\n",
    "    mlp_tower = Concatenate(axis=1)([profile_emb,category_emb, subcategory_emb])\n",
    "    mlp_tower = Flatten()(mlp_tower)\n",
    "    # Lstm-tower\n",
    "    lstm_tower = LSTM(40)(lstm_tower)\n",
    "    lstm_tower = Dropout(0.8)(lstm_tower)\n",
    "    lstm_tower = BatchNormalization(axis=1)(lstm_tower)\n",
    "    \n",
    "    # MLP tower\n",
    "    mlp_tower = Dense(2)(mlp_tower)\n",
    "    mlp_tower = Dropout(0.2)(mlp_tower)\n",
    "    mlp_tower = BatchNormalization(axis=1)(mlp_tower)\n",
    "    \n",
    "    # Click predictor\n",
    "    final = Concatenate()([lstm_tower,mlp_tower ])\n",
    "    final = BatchNormalization(axis=1)(final)\n",
    "    y = Dense(1, activation=\"sigmoid\")(final)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_history, user_profile_input, item_input, item_category, item_subcategory], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_arc4 = get_model_arc4(num_users, num_items, dims, num_categories,num_sub_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c016b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_history = df_train.iloc[:, 11:].values.astype(\"int64\")\n",
    "profile_input = df_train.iloc[:, 1:7].values.astype(\"int64\")\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1)).astype(\"int64\")\n",
    "labels = df_train.iloc[:, 10].values.reshape((-1,1)).astype(\"int64\")\n",
    "category_input = df_train.iloc[:, 8].values.reshape((-1,1)).astype(\"int64\")\n",
    "subcategory_input = df_train.iloc[:, 9].values.reshape((-1,1)).astype(\"int64\")\n",
    "print(user_history.shape,profile_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d75b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = merged[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=2\n",
    "for epoch in range(epochs):\n",
    "    hist = model_arc4.fit([user_history, profile_input, item_input,category_input, subcategory_input ], labels, epochs=1,validation_split=0.1, shuffle=True, verbose=1)    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc4( model_arc4, df_test, userid_to_true_item)\n",
    "    hits_list.append(np.average(hits))\n",
    "    ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    temp_hits = np.average(hits)\n",
    "    temp_ndcgs = np.average(ndcgs)\n",
    "    if (temp_hits > best_hits):\n",
    "        best_hits = temp_hits\n",
    "        best_ndcgs = temp_ndcgs\n",
    "        best_hits_five = np.average(hits_five)\n",
    "        best_ndcgs_five = np.average(ndcgs_five)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hit @ 10: {:.2f}\".format(best_hits))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(best_ndcgs))\n",
    "print(\"Hit @ 5: {:.2f}\".format(best_hits_five))\n",
    "print(\"ncdgs @ 5: {:.2f}\".format(best_ndcgs_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1b255",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_accuracy_results(\"arc4\", best_hits, best_ndcgs, best_hits_five, best_ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df06b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc4_accuracy.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ded015",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc4_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1388ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(hits_list)\n",
    "plt.plot(train_loss)\n",
    "plt.title('Hit ratio vs Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Hit@10', 'Train loss'], loc='upper left')\n",
    "plt.savefig(\"arc4_hit_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4163bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ec909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_arc4(user_id, df, model):\n",
    "    \n",
    "    ## Setup ###\n",
    "    user_profile = get_user_profile(df, user_id)\n",
    "    click_history = userid_to_article_history[user_id]\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_profile = np.tile(user_profile, display_items.shape[0]).reshape(-1, 6).astype(\"int64\")\n",
    "    category, sub_category = get_item_features(user_id)\n",
    "    user_ids = np.tile(np.array(user_id), display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    category = np.asarray(category).astype(\"int64\")\n",
    "    sub_category = np.asarray(sub_category).astype(\"int64\")\n",
    "    click_history = np.tile(click_history, display_items.shape[0]).reshape(-1, 30).astype(\"int64\")\n",
    "\n",
    "    ## Preds ###\n",
    "    predictions = model.predict([click_history, user_profile, display_items, category, sub_category])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items\n",
    "\n",
    "def predict_all_users_arc4(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "\n",
    "    counter = 0\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()):\n",
    "        top_ten_articles = get_recommendations(user_id, df)\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = get_user_profile(df_test, user_id)\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        counter += 1\n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten,category_hits_five,category_ndcg_five   = predict_all_users_arc4(df_test, model_arc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772950ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_category_results(\"arc4\", category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc59da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852905b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c261d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca601784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
