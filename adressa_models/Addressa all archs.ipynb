{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import scipy\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input,Flatten, Embedding, Reshape, Multiply, Dropout, Dense, Concatenate, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Layer, SpatialDropout1D, GlobalMaxPooling1D, Bidirectional, LSTM\n",
    "from tensorflow.keras.layers import Dot, TimeDistributed, BatchNormalization, multiply\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#import keras.backend as K\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle\n",
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f11c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/addressa/\"\n",
    "with open(PATH + \"articles.bin\", \"rb\") as f_in:\n",
    "    articles = pickle.load(f_in)\n",
    "# two different files: behaviors.bin and behaviors_two_days.bin\n",
    "with open(PATH + \"behaviors_7_days.bin\", \"rb\") as f_in:\n",
    "    behaviors = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640cffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame(np.random.randn(len(behaviors), 2))\n",
    "msk = np.random.rand(len(df_)) < 0.3\n",
    "print(len(behaviors))\n",
    "behaviors = behaviors[msk]\n",
    "print(len(behaviors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e497c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064136d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e5c3953",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors[\"time\"] = pd.to_datetime(behaviors[\"time\"], unit=\"s\")\n",
    "behaviors.drop(columns=[\"articleId\"], inplace=True)\n",
    "behaviors = behaviors.drop_duplicates([\"user\", \"id\"])\n",
    "\n",
    "behaviors = behaviors.drop(columns=[\"title\", \"author\"])\n",
    "articles.rename(columns={\"article_id\": \"id\"}, inplace=True)\n",
    "behaviors = behaviors.merge(articles, on=[\"id\"])\n",
    "\n",
    "# remove users which have fewer than 5 interacations\n",
    "print(\"Len before removal: \",len(behaviors))\n",
    "_keys = behaviors[\"user\"].value_counts()[behaviors[\"user\"].value_counts() > 2].keys()\n",
    "behaviors = behaviors[behaviors[\"user\"].isin(_keys)]\n",
    "print(\"Len after removal: \",len(behaviors))\n",
    "\n",
    "\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "article_enc = LabelEncoder()\n",
    "behaviors[\"user_id\"] = user_enc.fit_transform(behaviors[\"user\"].values)\n",
    "behaviors[\"article_id\"] = article_enc.fit_transform(behaviors[\"id\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0dd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Helper functions\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"norwegian\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def text_to_list(text):\n",
    "    text = text.split(\" \")\n",
    "    return text\n",
    "\n",
    "def take_one_category(text):\n",
    "    temp = text.split()\n",
    "    if len(temp) > 1:\n",
    "        return temp[1]\n",
    "    return temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(df):\n",
    "    df[\"title_cleaned\"] = df.title.apply(func = make_lower_case)\n",
    "    df[\"title_cleaned\"] = df.title_cleaned.apply(func = remove_stop_words)\n",
    "    df[\"title_cleaned\"] = df.title_cleaned.apply(func = remove_punctuation)\n",
    "    return df\n",
    "def hyphen_to_underline(category):\n",
    "    \"\"\"\n",
    "    Convert hyphen to underline for the subcategories. So that Tfidf works correctly\n",
    "    \"\"\"\n",
    "    return category.replace(\"-\",\"_\")\n",
    "#behaviors = clean_title(behaviors)\n",
    "behaviors[\"category_cleaned\"] = behaviors[\"kw_category\"].apply(func = take_one_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_enc = LabelEncoder()\n",
    "subcategory_enc = LabelEncoder()\n",
    "behaviors[\"category_int\"] = subcategory_enc.fit_transform(behaviors[\"category_cleaned\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = behaviors[\"user_id\"].unique()\n",
    "userid_to_profile = collections.defaultdict(list)\n",
    "for user_id in tqdm(users):\n",
    "    user_subcat = behaviors[behaviors[\"user_id\"] == user_id][\"category_int\"].values.tolist()\n",
    "    counter = Counter(user_subcat)\n",
    "    s = sorted(user_subcat, key=lambda x: (counter[x], x), reverse=True)\n",
    "    final_subcategories = []\n",
    "    for elem in s:\n",
    "        if elem not in final_subcategories:\n",
    "            final_subcategories.append(elem)\n",
    "    while len(final_subcategories) < 6:\n",
    "        final_subcategories.append(0)\n",
    "    userid_to_profile[user_id] = final_subcategories[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df799670",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = pd.DataFrame.from_dict(userid_to_profile, orient=\"index\")\n",
    "profile_df[\"user_id\"] = profile_df.index\n",
    "behaviors = behaviors.merge(profile_df, on=\"user_id\")\n",
    "behaviors = behaviors.rename(columns={\"0\": \"p0\",\"1\": \"p1\",\"2\": \"p2\",\"3\": \"p3\",\"4\": \"p4\",\"5\": \"p5\",})\n",
    "\n",
    "article_id_to_category_int = behaviors[[\"article_id\", \"category_int\"]].set_index(\"article_id\").to_dict()\n",
    "article_id_to_category_int = article_id_to_category_int[\"category_int\"]\n",
    "\n",
    "behaviors.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4debb",
   "metadata": {},
   "source": [
    "# 2. Train test spliit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ff145",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors[\"rank_latest\"] = behaviors.groupby([\"user_id\"])[\"time\"].rank(method=\"first\", ascending=False)\n",
    "\n",
    "train_true = behaviors[behaviors['rank_latest'] != 1]\n",
    "test_true = behaviors[behaviors['rank_latest'] == 1]\n",
    "\n",
    "rating = [1 for i in range(len(train_true))]\n",
    "train_true[\"label\"] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_userid_to_article_history(df):\n",
    "    userid_to_article_history = {}\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()):\n",
    "        click_history = df[df[\"user_id\"] == user_id][\"article_id\"].values\n",
    "        if len(click_history) < 10:\n",
    "            while len(click_history) < 10:\n",
    "                click_history = np.append(click_history, 0)\n",
    "        if len(click_history) > 10:\n",
    "            click_history = click_history[:10]\n",
    "        userid_to_article_history[user_id] = click_history\n",
    "    return userid_to_article_history\n",
    "userid_to_article_history = get_userid_to_article_history(train_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77926e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_article_ids = behaviors[\"article_id\"].unique()\n",
    "\n",
    "def negative_sampling(train_df, all_article_ids, user_id, article_id):\n",
    "    \"\"\"\n",
    "    Negative sample training instance; for each positive instance, add 4 negative articles\n",
    "    \n",
    "    Return user_ids, news_ids, category_1, category_2, authors_onehotencoded, titles\n",
    "    \"\"\"\n",
    "    \n",
    "    user_ids, user_click_history, articles, article_category, labels = [], [], [], [], []\n",
    "    p0, p1, p2, p3, p4, p5, p6, p7, p8, p9 = [], [], [], [], [], [], [], [], [], []\n",
    "    user_item_set = set(zip(train_df[user_id], \n",
    "                            train_df[article_id]))\n",
    "    num_negatives = 2\n",
    "\n",
    "    for (u, i) in tqdm(user_item_set):\n",
    "        user_ids.append(u)\n",
    "        user_click_history.append(userid_to_article_history[u])\n",
    "        profile = np.array(userid_to_profile[u])\n",
    "        p0.append(profile[0])\n",
    "        p1.append(profile[1])\n",
    "        p2.append(profile[2])\n",
    "        p3.append(profile[3])\n",
    "        p4.append(profile[4])\n",
    "        p5.append(profile[5])\n",
    "        article_category.append(article_id_to_category_int[i])\n",
    "        \n",
    "        \n",
    "        for _ in range(num_negatives):\n",
    "            negative_item = np.random.choice(all_article_ids)\n",
    "            while (u, negative_item) in user_item_set:\n",
    "                negative_item = np.random.choice(all_article_ids)\n",
    "            user_ids.append(u)\n",
    "            user_click_history.append(userid_to_article_history[u])\n",
    "            p0.append(profile[0])\n",
    "            p1.append(profile[1])\n",
    "            p2.append(profile[2])\n",
    "            p3.append(profile[3])\n",
    "            p4.append(profile[4])\n",
    "            p5.append(profile[5])\n",
    "            \n",
    "            article_category.append(article_id_to_category_int[negative_item])\n",
    "            \n",
    "            articles.append(negative_item)\n",
    "            labels.append(0)\n",
    "        articles.append(i)\n",
    "        labels.append(1)\n",
    "    \n",
    "    user_ids, user_click_history, p0, p1, p2, p3, p4, p5, articles,article_category, labels = shuffle(user_ids,user_click_history, p0, p1, p2, p3, p4, p5, articles,article_category, labels, random_state=0)\n",
    "\n",
    "    return pd.DataFrame(list(zip(user_ids,user_click_history,p0, p1, p2, p3, p4, p5, articles,article_category, labels)), columns=[\"user_id\",\"user_history\",\"p0\", \"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"article_id\",\"article_category\", \"labels\"])\n",
    "\n",
    "\n",
    "\n",
    "df_train = negative_sampling(train_true, all_article_ids, \"user_id\", \"article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06639b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dftrain(df, column, max_len, padding):\n",
    "    i = 0\n",
    "    for i in tqdm(range(max_len)):\n",
    "        df[column + \"_\" + str(i)] = df[column].apply(lambda x: x[i] if i < len(x) else padding)\n",
    "    #df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train = fix_dftrain(df_train, \"user_history\", 10, 0)\n",
    "df_train.drop(columns=[\"user_history\"], inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b7226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each user; for each item the user has interacted with in the test set;\n",
    "    # Sample 99 items the user has not interacted with in the past and add the one test item  \n",
    "    \n",
    "def negative_sample_testset(ordiginal_df, df_test, all_article_ids, user_id, article_id):\n",
    "    test_user_item_set = set(zip(df_test[user_id], df_test[article_id]))\n",
    "    user_interacted_items = ordiginal_df.groupby(user_id)[article_id].apply(list).to_dict()\n",
    "    users = []\n",
    "    p0, p1, p2, p3, p4, p5, p6, p7, p8, p9 = [], [], [], [], [], [], [], [], [], []\n",
    "    res_arr = []\n",
    "    article_category, article_sub_category = [], []\n",
    "    \n",
    "    userid_to_true_item = {} # keep track of the real items\n",
    "    for (u,i) in tqdm(test_user_item_set):\n",
    "        interacted_items = user_interacted_items[u]\n",
    "        not_interacted_items = set(all_article_ids) - set(interacted_items)\n",
    "        selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "        test_items =[i] + selected_not_interacted \n",
    "        temp = []\n",
    "        profile = userid_to_profile[u]\n",
    "        for j in range(len(test_items)):\n",
    "            temp.append([u,\n",
    "                         userid_to_article_history[u], \n",
    "                         profile[0],\n",
    "                         profile[1],\n",
    "                         profile[2],\n",
    "                         profile[3],\n",
    "                         profile[4],\n",
    "                         profile[5], \n",
    "                         test_items[j], article_id_to_category_int[test_items[j]]])\n",
    "        #            user_click_history.append(userid_to_article_history[u])\n",
    "\n",
    "        res_arr.append(temp)\n",
    "        userid_to_true_item[u] = i \n",
    "    X_test = np.array(res_arr)\n",
    "    X_test = X_test.reshape(-1, X_test.shape[-1])\n",
    "    df_test = pd.DataFrame(X_test, columns=[\"user_id\",\n",
    "                                            \"click_history\", \n",
    "                                            \"p0\", \n",
    "                                            \"p1\", \n",
    "                                            \"p2\", \n",
    "                                            \"p3\", \n",
    "                                            \"p4\", \n",
    "                                            \"p5\",\n",
    "                                            \"article_id\", \n",
    "                                            \"category\"])\n",
    "    return X_test, df_test, userid_to_true_item\n",
    "X_test, df_test, userid_to_true_item = negative_sample_testset(behaviors, test_true, behaviors[\"article_id\"].unique(), \"user_id\", \"article_id\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dftest(df, column, max_len, padding):\n",
    "    i = 0\n",
    "    for i in tqdm(range(max_len)):\n",
    "        df[column + \"_\" + str(i)] = df[column].apply(lambda x: x[i] if i < len(x) else padding)\n",
    "    #df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_test = fix_dftest(df_test, \"click_history\", 10, 0)\n",
    "df_test.drop(columns=[\"click_history\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            print(\"test iteem: \", item)\n",
    "            print(\"truee item\", gtItem)\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_train[df_train[\"article_id\"] == 46734][[\"user_id\"]][\"user_id\"] == 3398).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa709dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test[\"article_id\"] == 3851]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6333c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45f5951e",
   "metadata": {},
   "source": [
    "# 4. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d274c5",
   "metadata": {},
   "source": [
    "# 4.1 Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a103ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_final(model, user_id, user_profiles, all_articles,user_clicks, true_item, categories):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    #expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    #user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    predictions = model.predict([user_clicks, user_profiles, all_articles, categories]) #TODO: add categories, sub_cat\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg,hr_five,ndcg_five\n",
    "\n",
    "def evalaute_model_final(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five = []\n",
    "    ndcgs_five = []\n",
    "    users = df_test[\"user_id\"].unique()[:800]\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].values.astype(\"int64\")# get the user_profile\n",
    "        user_clicks = user_df.iloc[:, 9:].values.astype(\"int64\")\n",
    "        categories = user_df.iloc[:, 8].values.astype(\"int64\")\n",
    "        \n",
    "        ht, ndcg, ht_five, ndcg_five = evaluate_one_rating_final(model, \n",
    "                                       user_id, \n",
    "                                       user_profiles, \n",
    "                                       all_articles,user_clicks, \n",
    "                                       true_item, \n",
    "                                       categories, \n",
    "                                       )\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(ht_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs,hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "num_users = len(behaviors[\"user_id\"].unique())\n",
    "num_items = len(behaviors[\"article_id\"].unique()) \n",
    "dims = 20\n",
    "num_categories = len(behaviors[\"category_int\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_users, num_items, dims,num_categories, dense_layers=[128, 64, 32, 8]):\n",
    "    #User features\n",
    "    user_history = Input(shape=(10,), name=\"user\")\n",
    "    user_profile_input = Input(shape=(6,), name=\"profile\")\n",
    "    #item features\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    item_category = Input(shape=(1,), name=\"category\")\n",
    "    item_subcategory = Input(shape=(1,), name=\"subcategory\")\n",
    "    \n",
    "    # User emb\n",
    "    click_history_emb = Embedding(output_dim=dims, \n",
    "                                  input_dim=num_items+1, \n",
    "                                  input_length=10,\n",
    "                                  embeddings_initializer='he_normal', \n",
    "                                  embeddings_regularizer=regularizers.l2(0.001), \n",
    "                                  name=\"mf_user_emb\")(user_history)\n",
    "    profile_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_categories, \n",
    "                            input_length=6, \n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            name=\"mf_profile_emb\")(user_profile_input)\n",
    "    \n",
    "    # Item emb\n",
    "    item_emb = Embedding(output_dim=dims, \n",
    "                         input_dim=num_items+1, \n",
    "                         input_length=1,\n",
    "                         embeddings_initializer='he_normal', \n",
    "                         embeddings_regularizer=regularizers.l2(0.001), \n",
    "                         name=\"mf_item_emb\")(item_input)\n",
    "    category_emb = Embedding(output_dim=dims, \n",
    "                             input_dim=num_categories, \n",
    "                             input_length=1,\n",
    "                             embeddings_initializer='he_normal', \n",
    "                             embeddings_regularizer=regularizers.l2(0.001),\n",
    "                             name=\"cat_emb\")(item_category)\n",
    "    \n",
    "    ### Wide\n",
    "    #wide_history = Flatten()(click_history_emb)\n",
    "    #wide_item = Flatten()(item_input)\n",
    "    wide = Concatenate(axis=1)([click_history_emb, item_emb])\n",
    "    wide = Flatten()(wide)\n",
    "    y_wide = Dense(2)(wide)\n",
    "    \n",
    "    ### Deep\n",
    "    deep_features = Concatenate(axis=1)([category_emb, profile_emb])\n",
    "    x_deep = LSTM(40)(deep_features)\n",
    "    \n",
    "    print(x_deep.shape)\n",
    "    print(y_wide.shape)\n",
    "    \n",
    "    final = Concatenate()([x_deep, y_wide])\n",
    "    final = BatchNormalization(axis=1)(final)\n",
    "   \n",
    "    y = Dense(1, activation=\"sigmoid\")(final)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_history, user_profile_input, item_input, item_category], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_final = get_model(num_users, num_items, dims, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54215a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_history = df_train.iloc[:, 10:].values.astype(\"int64\")\n",
    "profile_input = df_train.iloc[:, 1:7].values.astype(\"int64\")\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1)).astype(\"int64\")\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1,1)).astype(\"int64\")\n",
    "category_input = df_train.iloc[:, 8].values.reshape((-1,1)).astype(\"int64\")\n",
    "print(user_history.shape,profile_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = behaviors[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "    hist = model_final.fit([user_history, profile_input, item_input,category_input ], labels, epochs=1,validation_split=0.1, shuffle=True, verbose=1, batch_size=32)    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    #hits, ndcgs, hits_five, ndcgs_five = evalaute_model_final( model_final, df_test[:10000], userid_to_true_item)\n",
    "    #hits_list.append(np.average(hits))\n",
    "    #ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    #temp_hits = np.average(hits)\n",
    "    #temp_ndcgs = np.average(ndcgs)\n",
    "    #if (temp_hits > best_hits):\n",
    "    #    best_hits = temp_hits\n",
    "    #    best_ndcgs = temp_ndcgs\n",
    "    #    best_hits_five = np.average(hits_five)\n",
    "    #    best_ndcgs_five = np.average(ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4200de",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, ndcgs, hits_five, ndcgs_five = evalaute_model_final( model_final, df_test, userid_to_true_item)\n",
    "\n",
    "print(\"Hit @ 10: {:.2f}\".format(np.average(hits)))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(np.average(ndcgs)))\n",
    "print(\"Hit @ 10: {:.2f}\".format(np.average(hits_five)))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(np.average(ndcgs_five)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6578949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"final_accuracy.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"final_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(hits_list)\n",
    "plt.plot(train_loss)\n",
    "plt.title('Hit ratio vs Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Hit@10', 'Train loss'], loc='upper left')\n",
    "plt.savefig(\"final_hit_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a372a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_category(article_id):\n",
    "    return merged[merged[\"article_id\"] == article_id][\"subcategory_cleaned\"].values[0]\n",
    "def get_userprofile_to_name(user_id, id_to_subcategory):\n",
    "    \"\"\"\n",
    "    Return array of strings with category names\n",
    "    \"\"\"\n",
    "    arr_profile = get_user_profile(df_train,user_id )\n",
    "    return [id_to_subcategory[elem] for elem in arr_profile]\n",
    "def get_user_profile(df, user_id):\n",
    "    \"\"\"\n",
    "    Return the user profile given user_id\n",
    "    \"\"\"\n",
    "    return df[df[\"user_id\"] == user_id].iloc[0, 1:7].values\n",
    "def get_article_content(article_id):\n",
    "    article = merged[merged[\"article_id\"] == article_id].head(1)\n",
    "    title = article[\"title\"].values[0]\n",
    "    sub_category = article[\"sub_category\"].values[0]\n",
    "    return title, sub_category\n",
    "\n",
    "def get_item_features(user_id):\n",
    "    d = df_test[df_test[\"user_id\"] == user_id]\n",
    "    return d[\"category\"].values.reshape(-1,1)\n",
    "\n",
    "def get_item_features_one_item(article_id):\n",
    "    d = df_test[df_test[\"article_id\"] == article_id]\n",
    "    return np.array(d[\"category\"].values[0]), np.array(d[\"sub_category\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c23ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_category(article_id, df):\n",
    "    \"\"\"\n",
    "    Return the article's category\n",
    "        type: int\n",
    "    \"\"\"\n",
    "    return df[df[\"article_id\"] == article_id][\"category\"].values[0]\n",
    "def get_article_subcategory(article_id, df):\n",
    "    \"\"\"\n",
    "    Return the article's category\n",
    "        type: int\n",
    "    \"\"\"\n",
    "    return df[df[\"article_id\"] == article_id][\"category\"].values[0]\n",
    "def get_category_hit_ratio(user_profile, top_ten_categories):\n",
    "    num_hits = 0\n",
    "    for profile in user_profile:\n",
    "        for category in top_ten_categories:\n",
    "            if profile == category:\n",
    "                num_hits+= 1\n",
    "    \n",
    "    return num_hits\n",
    "def get_ndcgs_category(user_profile, top_ten_categories):\n",
    "    for i in range(len(top_ten_categories)):\n",
    "        item = top_ten_categories[i]\n",
    "        for profile in user_profile:\n",
    "            if item == profile:\n",
    "                return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae218b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id, df, model):\n",
    "    \n",
    "    ## Setup ###\n",
    "    user_profile = get_user_profile(df, user_id)\n",
    "    click_history = userid_to_article_history[user_id]\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_profile = np.tile(user_profile, display_items.shape[0]).reshape(-1, 6).astype(\"int64\")\n",
    "    category = get_item_features(user_id)\n",
    "    user_ids = np.tile(np.array(user_id), display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    category = np.asarray(category).astype(\"int64\")\n",
    "    click_history = np.tile(click_history, display_items.shape[0]).reshape(-1, 30).astype(\"int64\")\n",
    "\n",
    "    ## Preds ###\n",
    "    predictions = model.predict([click_history, user_profile, display_items, category,])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_users(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "\n",
    "    counter = 0\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()[:800]):\n",
    "        top_ten_articles = get_recommendations(user_id, df, model)\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = get_user_profile(df_test, user_id)\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        counter += 1\n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten,category_hits_five,category_ndcg_five   = predict_all_users(df_test,model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbacc56",
   "metadata": {},
   "source": [
    "# 4.2 Arch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_arc1(model, user_id, all_articles, true_item):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    predictions = model.predict([expanded_user_id, all_articles])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg, hr_five, ndcg_five\n",
    "\n",
    "def evalaute_model_arc1(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        \n",
    "        \n",
    "        ht, ndcg, hr_five, ndcg_five = evaluate_one_rating_arc1(model, user_id, all_articles, true_item)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(hr_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs, hits_five, ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "def get_model(num_users, num_items, dims, dense_layers=[128, 64, 32, 8]):\n",
    "    user_input = Input(shape=(1,), name=\"user\")\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    \n",
    "    user_emb = Embedding(output_dim=dims, \n",
    "                         input_dim=num_users, \n",
    "                         input_length=1,\n",
    "                         embeddings_initializer='he_normal', \n",
    "                         embeddings_regularizer=regularizers.l2(0.001),\n",
    "                         name=\"mf_user_emb\")(user_input)\n",
    "    item_emb = Embedding(output_dim=dims, \n",
    "                         input_dim=num_items, \n",
    "                         input_length=1,\n",
    "                         embeddings_initializer='he_normal', \n",
    "                         embeddings_regularizer=regularizers.l2(0.001),\n",
    "                         name=\"mf_item_emb\")(item_input)\n",
    "    \n",
    "    user_vecs = Flatten()(user_emb)\n",
    "    item_vecs = Flatten()(item_emb)\n",
    "    \n",
    "    #y = Multiply()([user_vecs, item_vecs])\n",
    "    y = Dot(1, normalize=False)([user_vecs, item_vecs])\n",
    "    \n",
    "    y = Dense(1, activation=\"sigmoid\")(y)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_input, item_input], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_arc1 = get_model(num_users, num_items, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a788d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "item_input = df_train.iloc[:, 6].values.reshape((-1,1))\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1,1))\n",
    "print(user_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278c905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6db17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = df_train[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "\n",
    "epochs=6\n",
    "for epoch in range(epochs):\n",
    "    hist = model_arc1.fit([user_input, item_input], labels, epochs=1, shuffle=True, verbose=1, validation_split=0.1)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    #hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc1( model_arc1, df_test, userid_to_true_item)\n",
    "    #hits_list.append(np.average(hits))\n",
    "    #ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    #temp_hits = np.average(hits)\n",
    "    #temp_ndcgs = np.average(ndcgs)\n",
    "    #if (temp_hits > best_hits):\n",
    "    #    best_hits = temp_hits\n",
    "    #    best_ndcgs = temp_ndcgs\n",
    "    #    best_hits_five = np.average(hits_five)\n",
    "    #    best_ndcgs_five = np.average(ndcgs_five)\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d70942",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc1( model_arc1, df_test, userid_to_true_item)\n",
    "print(np.average(hits))\n",
    "print(np.average(ndcgs))\n",
    "print(np.average(hits_five))\n",
    "print(np.average(ndcgs_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc1_accuracy.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73013ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc1_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe891ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_arc1(user_id, df, model):\n",
    "    \n",
    "    ## Setup ###\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_ids = np.tile(np.array(user_id), display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    \n",
    "    ## Preds ###\n",
    "    predictions = model.predict([user_ids, display_items])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_hits_ndcg_arc1(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    \n",
    "    for user_id in tqdm(df[\"user_id\"].unique()[:800]):\n",
    "        top_ten_articles = get_recommendations_arc1(user_id, df, model)\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = userid_to_profile[user_id]\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        \n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        \n",
    "        \n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five = get_category_hits_ndcg_arc1(df_test,model_arc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887dca5a",
   "metadata": {},
   "source": [
    "# 4.3 NeuMF all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_neumffeatures(model, user_id, user_profiles, all_articles,user_clicks, true_item, categories, user_ids):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    #expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    #user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    predictions = model.predict([user_ids,user_clicks, user_profiles, all_articles, categories]) #TODO: add categories, sub_cat\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg,hr_five,ndcg_five\n",
    "\n",
    "def evalaute_model_neumffeatures(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five = []\n",
    "    ndcgs_five = []\n",
    "    users = df_test[\"user_id\"].unique()\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].values.astype(\"int64\")# get the user_profile\n",
    "        user_clicks = user_df.iloc[:, 9:].values.astype(\"int64\")\n",
    "        categories = user_df.iloc[:, 8].values.astype(\"int64\")\n",
    "        user_ids = np.tile(user_id, all_articles.shape[0]).reshape(-1,1).astype(int)\n",
    "        \n",
    "        ht, ndcg, ht_five, ndcg_five = evaluate_one_rating_neumffeatures(model, \n",
    "                                       user_id, \n",
    "                                       user_profiles, \n",
    "                                       all_articles,\n",
    "                                       user_clicks, \n",
    "                                       true_item, \n",
    "                                       categories, \n",
    "                                       user_ids)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(ht_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs,hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526db4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_neumffeatures(num_users, num_items, dims, dense_layers=[128, 64, 32, 8]):\n",
    "    user_input = Input(shape=(1,), name=\"user_input\")\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    user_history = Input(shape=(10,), name=\"user\")\n",
    "    user_profile_input = Input(shape=(6,), name=\"profile\")\n",
    "    #item features\n",
    "    item_category = Input(shape=(1,), name=\"category\")\n",
    "    \n",
    "    \n",
    "    mf_user_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_users, \n",
    "                            input_length=1, \n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            name=\"mf_user_emb\")(user_input)\n",
    "    mf_item_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_items,\n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            input_length=1, name=\"mf_item_emb\")(item_input)\n",
    "    \n",
    "    num_layers = len(dense_layers)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # User emb\n",
    "    mlp_click_history_emb = Embedding(output_dim=int(dense_layers[0] / 2), input_dim=num_items+1, input_length=10, name=\"mlp_user_emb\")(user_history)\n",
    "    mlp_profile_emb = Embedding(output_dim=int(dense_layers[0] / 2), input_dim=num_categories, input_length=6, name=\"mlp_profile_emb\")(user_profile_input)\n",
    "    \n",
    "    # Item emb\n",
    "    mlp_item_emb = Embedding(output_dim=int(dense_layers[0] / 2), input_dim=num_items+1, input_length=1, name=\"mlp_item_emb\")(item_input)\n",
    "    mlp_category_emb = Embedding(output_dim=int(dense_layers[0] / 2), input_dim=num_categories, input_length=1, name=\"cat_emb\")(item_category)\n",
    "    \n",
    "    ### Wide\n",
    "    wide = Concatenate(axis=1)([mlp_click_history_emb,mlp_profile_emb,mlp_item_emb,mlp_category_emb ])\n",
    "    mlp_vector = Flatten()(wide)\n",
    "    \n",
    "    # Matrix factorization\n",
    "    mf_user_vecs = Flatten()(mf_user_emb)\n",
    "    mf_item_vecs = Flatten()(mf_item_emb)\n",
    "    mf_vec = multiply([mf_user_vecs, mf_item_vecs])\n",
    "    \n",
    "    \n",
    "    for num_nodes in dense_layers:\n",
    "        l = Dense(num_nodes, activation=\"relu\")\n",
    "        mlp_vector = l(mlp_vector)\n",
    "    \n",
    "    y = Concatenate()([mf_vec, mlp_vector])\n",
    "    y = Dense(1, activation=\"sigmoid\", name=\"pred\")(y)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_input,user_history, user_profile_input, item_input,item_category], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_neumffeatures = get_model_neumffeatures(num_users, num_items, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c206a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_ids = df_train.iloc[:,0].values.astype(\"int64\")\n",
    "user_history = df_train.iloc[:, 10:].values.astype(\"int64\")\n",
    "profile_input = df_train.iloc[:, 1:7].values.astype(\"int64\")\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1)).astype(\"int64\")\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1,1)).astype(\"int64\")\n",
    "category_input = df_train.iloc[:, 8].values.reshape((-1,1)).astype(\"int64\")\n",
    "print(user_history.shape,profile_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=4\n",
    "for epoch in range(epochs):\n",
    "    hist = model_neumffeatures.fit([user_ids, user_history, profile_input, item_input,category_input ], labels, epochs=1,validation_split=0.1, shuffle=True, verbose=1, batch_size=512)    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    #hits, ndcgs, hits_five, ndcgs_five = evalaute_model( model_final, df_test[:10000], userid_to_true_item)\n",
    "    #hits_list.append(np.average(hits))\n",
    "    #ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    #temp_hits = np.average(hits)\n",
    "    #temp_ndcgs = np.average(ndcgs)\n",
    "    #if (temp_hits > best_hits):\n",
    "    #    best_hits = temp_hits\n",
    "    #    best_ndcgs = temp_ndcgs\n",
    "    #    best_hits_five = np.average(hits_five)\n",
    "    #    best_ndcgs_five = np.average(ndcgs_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81df337",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, ndcgs, hits_five, ndcgs_five = evalaute_model_neumffeatures( model_neumffeatures, df_test, userid_to_true_item)\n",
    "print(np.average(hits))\n",
    "print(np.average(ndcgs))\n",
    "print(np.average(hits_five))\n",
    "print(np.average(ndcgs_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a875cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc4_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6819e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_neumffeatures(user_id, df, model):\n",
    "    #user_history, profile_input, item_input\n",
    "    ## Setup ###\n",
    "    #user_ids, user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    \n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    click_history = userid_to_article_history[user_id]\n",
    "    click_history = np.tile(click_history, display_items.shape[0]).reshape(-1, 30).astype(\"int64\")\n",
    "    category = get_item_features(user_id)\n",
    "    user_profile = get_user_profile(df, user_id)\n",
    "    user_profile = np.tile(user_profile, display_items.shape[0]).reshape(-1, 6).astype(\"int64\")\n",
    "    user_id_input = np.tile(user_id, display_items.shape[0]).reshape(-1, 1).astype(\"int64\")\n",
    "    category = np.asarray(category).astype(\"int64\")\n",
    "    ## Preds ###\n",
    "    predictions = model.predict([user_id_input,click_history, user_profile,display_items, category ])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a82343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_hits_ndcg_neumffeatures(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    \n",
    "    for user_id in tqdm(df[\"user_id\"].unique()[:200]):\n",
    "        top_ten_articles = get_recommendations_neumffeatures(user_id, df, model)\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = userid_to_profile[user_id]\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        \n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        \n",
    "        \n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five = get_category_hits_ndcg_neumffeatures(df_test, model_neumffeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f34a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682da3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a63212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5abfda7",
   "metadata": {},
   "source": [
    "# 4.2 Arch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877917b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_arc2(model, user_id, user_profiles, all_articles,user_clicks, true_item):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    #expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    predictions = model.predict([user_clicks, user_profiles, all_articles])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg, hr_five,ndcg_five\n",
    "\n",
    "def evalaute_model_arc2(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].values.astype(\"int64\")# get the user_profile\n",
    "        user_clicks = user_df.iloc[:, 9:].values.astype(\"int64\")\n",
    "        \n",
    "        ht, ndcg,hr_five,ndcg_five = evaluate_one_rating_arc2(model, user_id, user_profiles, all_articles,user_clicks, true_item)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(hr_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs,hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4022cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2dcecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "def get_model_arc2(num_users, num_items, dims, dense_layers=[128, 64, 32, 8]):\n",
    "    user_history = Input(shape=(30,), name=\"user\")\n",
    "    user_profile_input = Input(shape=(6,), name=\"profile\")\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    \n",
    "    mf_user_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_items, \n",
    "                            input_length=30, \n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            name=\"mf_user_emb\")(user_history)\n",
    "    mf_profile_emb = Embedding(output_dim=dims, \n",
    "                               input_dim=num_categories, \n",
    "                               input_length=6, \n",
    "                               embeddings_initializer='he_normal', \n",
    "                               embeddings_regularizer=regularizers.l2(0.001),\n",
    "                               name=\"mf_profile_emb\")(user_profile_input)\n",
    "    mf_item_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_items, \n",
    "                            input_length=1,\n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            name=\"mf_item_emb\")(item_input)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #profile_emb = GlobalAveragePooling1D()(mf_profile_emb)\n",
    "    profile_vecs = Flatten()(mf_user_emb)\n",
    "    user_vecs = Flatten()(mf_profile_emb)\n",
    "    item_vecs = Reshape([dims])(mf_item_emb)\n",
    "    \n",
    "    user_vecs_complete = Concatenate(axis=1)([user_vecs, profile_vecs])\n",
    "    input_vecs = Concatenate()([user_vecs_complete, item_vecs])\n",
    "    x = Dense(128, activation=\"relu\", name=\"dense_0\")(input_vecs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(1, activation=\"sigmoid\", name=\"prediction\")(x)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_history, user_profile_input, item_input], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_arc2 = get_model_arc2(num_users, num_items, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc418a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_history = df_train.iloc[:, 10:].values.astype(\"int64\")\n",
    "profile_input = df_train.iloc[:, 1:7].values.astype(\"int64\")\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1)).astype(\"int64\")\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1,1)).astype(\"int64\")\n",
    "print(user_history.shape,profile_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a002298",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = behaviors[\"user_id\"].unique()\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=6\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hist = model_arc2.fit([user_history, profile_input, item_input], labels, epochs=1, shuffle=True, verbose=1, validation_split=0.1)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    #hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc2( model_arc2, df_test, userid_to_true_item)\n",
    "    #hits_list.append(np.average(hits))\n",
    "    #ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    #temp_hits = np.average(hits)\n",
    "    #temp_ndcgs = np.average(ndcgs)\n",
    "    #if (temp_hits > best_hits):\n",
    "    #    best_hits = temp_hits\n",
    "    #    best_hits_five = np.average(hits_five)\n",
    "    #    best_ndcgs_five = np.average(ndcgs_five)\n",
    "    #    best_ndcgs = temp_ndcgs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc2( model_arc2, df_test, userid_to_true_item)\n",
    "print(np.average(hits))\n",
    "print(np.average(ndcgs))\n",
    "print(np.average(hits_five))\n",
    "print(np.average(ndcgs_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc2_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(hits_list)\n",
    "plt.plot(train_loss)\n",
    "plt.title('Hit ratio vs Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Hit@10', 'Train loss'], loc='upper left')\n",
    "plt.savefig(\"arc2_hit_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_arc2(user_id, df, model):\n",
    "    #user_history, profile_input, item_input\n",
    "    ## Setup ###\n",
    "    \n",
    "    click_history = userid_to_article_history[user_id]\n",
    "    user_profile = get_user_profile(df, user_id)\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_profile = np.tile(user_profile, display_items.shape[0]).reshape(-1, 6).astype(\"int64\")\n",
    "    click_history = np.tile(np.array(click_history), display_items.shape[0]).reshape(-1,30).astype(\"int64\")\n",
    "    \n",
    "    ## Preds ###\n",
    "    predictions = model.predict([click_history, user_profile,display_items])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_hits_ndcg_arc2(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    \n",
    "    for user_id in tqdm(df[\"user_id\"].unique()[:100]):\n",
    "        top_ten_articles = get_recommendations_arc2(user_id, df, model)\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = userid_to_profile[user_id]\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        \n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        \n",
    "        \n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten, category_hits_five, category_ndcg_five = get_category_hits_ndcg_arc2(df_test, model_arc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377636f3",
   "metadata": {},
   "source": [
    "# 4.3 Arch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880dbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_arc3(model, user_id, user_profiles, all_articles,user_clicks, true_item, categories):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    #expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    #user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    predictions = model.predict([user_clicks, user_profiles, all_articles, categories]) #TODO: add categories, sub_cat\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg, hr_five,ndcg_five \n",
    "\n",
    "def evalaute_model_arc3(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    users = df_test[\"user_id\"].unique()[:800]\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].values.astype(\"int64\")# get the user_profile\n",
    "        user_clicks = user_df.iloc[:, 9:].values.astype(\"int64\")\n",
    "        categories = user_df.iloc[:, 8].values.astype(\"int64\")\n",
    "        \n",
    "        ht, ndcg, hr_five,ndcg_five = evaluate_one_rating_arc3(model, \n",
    "                                       user_id, \n",
    "                                       user_profiles, \n",
    "                                       all_articles,user_clicks, \n",
    "                                       true_item, \n",
    "                                       categories)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(hr_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs, hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fde66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "def get_model_arc3(num_users, num_items, dims,num_categories, dense_layers=[128, 64, 32, 8]):\n",
    "    #User features\n",
    "    user_history = Input(shape=(30,), name=\"user\")\n",
    "    user_profile_input = Input(shape=(6,), name=\"profile\")\n",
    "    #item features\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    item_category = Input(shape=(1,), name=\"category\")\n",
    "    \n",
    "    # User emb\n",
    "    click_history_emb = Embedding(output_dim=dims, input_dim=num_items, input_length=30, name=\"mf_user_emb\")(user_history)\n",
    "    profile_emb = Embedding(output_dim=dims, input_dim=num_categories, input_length=6, name=\"mf_profile_emb\")(user_profile_input)\n",
    "    \n",
    "    #user_features = Concatenate(axis=1)([click_history_emb,profile_emb])\n",
    "    \n",
    "    # Item emb\n",
    "    item_emb = Embedding(output_dim=dims, input_dim=num_items, input_length=1, name=\"mf_item_emb\")(item_input)\n",
    "    category_emb = Embedding(output_dim=dims, input_dim=num_categories, input_length=1, name=\"cat_emb\")(item_category)\n",
    "    \n",
    "    item_features = Concatenate(axis=1)([item_emb,category_emb, profile_emb])\n",
    "    \n",
    "    # User-tower\n",
    "    user_lstm = LSTM(40)(click_history_emb)\n",
    "    user_lstm = Dropout(0.5)(user_lstm)\n",
    "    user_lstm = BatchNormalization(axis=1)(user_lstm)\n",
    "    \n",
    "    # Item tower\n",
    "    item_dense = Flatten()(item_features)\n",
    "    item_dense = Dense(128)(item_dense)\n",
    "    item_dense = Dropout(0.5)(item_dense)\n",
    "    item_dense = BatchNormalization(axis=1)(item_dense)\n",
    "    \n",
    "    # Click predictor\n",
    "    final = Concatenate()([user_lstm,item_dense ])\n",
    "    y = Dense(1, activation=\"sigmoid\")(final)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_history, user_profile_input, item_input, item_category], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_arc3 = get_model_arc3(num_users, num_items, dims, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_history = df_train.iloc[:, 10:].values.astype(\"int64\")\n",
    "profile_input = df_train.iloc[:, 1:7].values.astype(\"int64\")\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1)).astype(\"int64\")\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1,1)).astype(\"int64\")\n",
    "category_input = df_train.iloc[:, 8].values.reshape((-1,1)).astype(\"int64\")\n",
    "print(user_history.shape,profile_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d318781",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = behaviors[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=6\n",
    "for epoch in range(epochs):\n",
    "    hist = model_arc3.fit([user_history, profile_input, item_input,category_input ], labels, validation_split=0.1, epochs=1, shuffle=True, verbose=1)\n",
    "    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    #hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc3( model_arc3, df_test, userid_to_true_item)\n",
    "    #hits_list.append(np.average(hits))\n",
    "    #ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    #temp_hits = np.average(hits)\n",
    "    #temp_ndcgs = np.average(ndcgs)\n",
    "    #if (temp_hits > best_hits):\n",
    "    #    best_hits = temp_hits\n",
    "    #    best_hits_five = np.average(hits_five)\n",
    "    #    best_ndcgs_five = np.average(ndcgs_five)\n",
    "    #    best_ndcgs = temp_ndcgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63250afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc3( model_arc3, df_test, userid_to_true_item)\n",
    "print(\"Hit @ 10: {:.2f}\".format(np.average(hits)))\n",
    "print(\"ncdgs @ 10: {:.2f}\".format(np.average(ndcgs)))\n",
    "print(\"Hit @ 5: {:.2f}\".format(np.average(hits_five)))\n",
    "print(\"ncdgs @ 5: {:.2f}\".format(np.average(ndcgs_five)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61766889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9106a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc3_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204a042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_arc3(user_id, df,model):\n",
    "    #user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    ## Setup ###\n",
    "    click_history = userid_to_article_history[user_id]\n",
    "    user_profile = get_user_profile(df, user_id)\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_profile = np.tile(user_profile, display_items.shape[0]).reshape(-1, 6).astype(\"int64\")\n",
    "    category = get_item_features(user_id)\n",
    "    click_history = np.tile(np.array(click_history), display_items.shape[0]).reshape(-1,30).astype(\"int64\")\n",
    "    category = np.asarray(category).astype(\"int64\")\n",
    "    #category = np.tile(category, display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    #sub_category = np.tile(sub_category, display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    \n",
    "    ## Preds ###\n",
    "    predictions = model.predict([click_history, user_profile, display_items, category])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items\n",
    "\n",
    "def predict_all_users_arc3(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "    counter = 0\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()[:800]):\n",
    "        top_ten_articles = get_recommendations_arc3(user_id, df, model)\n",
    "        assert len(top_ten_articles) == 10\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = get_user_profile(df_test, user_id)\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        counter += 1\n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten,category_hits_five,category_ndcg_five   = predict_all_users_arc3(df_test, model_arc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ccb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fd70ed",
   "metadata": {},
   "source": [
    "# 4.4 Arch 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_rating_arc6(model, user_id, user_profiles, all_articles,user_clicks, true_item, categories):\n",
    "    ### Reshaping to make it on the right shape ###\n",
    "    #expanded_user_id = np.array([user_id]*100).reshape((100,1))\n",
    "    all_articles = np.array(all_articles).reshape(-1,1)\n",
    "    \n",
    "    # predictions\n",
    "    #user_history, profile_input, item_input,category_input, subcategory_input\n",
    "    predictions = model.predict([user_clicks, user_profiles, all_articles, categories]) #TODO: add categories, sub_cat\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [all_articles[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    hr = getHitRatio(top_ten_items, true_item)\n",
    "    ndcg = getNDCG(top_ten_items, true_item)\n",
    "    hr_five = getHitRatio(top_ten_items[:5], true_item)\n",
    "    ndcg_five = getNDCG(top_ten_items[:5], true_item)\n",
    "    return hr, ndcg,hr_five,ndcg_five\n",
    "\n",
    "def evalaute_model_arc6(model, df_test, userid_to_true_item):\n",
    "    print(\"Evaluate model\")\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    hits_five = []\n",
    "    ndcgs_five = []\n",
    "    users = df_test[\"user_id\"].unique()[:800]\n",
    "    for user_id in tqdm(users):\n",
    "        user_df = df_test[df_test[\"user_id\"] == user_id] # get the 100 samples for this user\n",
    "        true_item = userid_to_true_item[user_id] # get the actual true item in the test set\n",
    "        all_articles = user_df[\"article_id\"].values.astype(\"int64\") # get all possible articles\n",
    "        user_profiles = user_df.iloc[:, 1:7].values.astype(\"int64\")# get the user_profile\n",
    "        user_clicks = user_df.iloc[:, 9:].values.astype(\"int64\")\n",
    "        categories = user_df.iloc[:, 8].values.astype(\"int64\")\n",
    "        \n",
    "        ht, ndcg, hr_five, ndcg_five = evaluate_one_rating_arc6(model, \n",
    "                                       user_id, \n",
    "                                       user_profiles, \n",
    "                                       all_articles,user_clicks, \n",
    "                                       true_item, \n",
    "                                       categories)\n",
    "        hits.append(ht)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits_five.append(hr_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "    return hits, ndcgs, hits_five,ndcgs_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ad890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "def get_model_arc6(num_users, num_items, dims,num_categories, dense_layers=[128, 64, 32, 8]):\n",
    "    #User features\n",
    "    user_history = Input(shape=(30,), name=\"user\")\n",
    "    user_profile_input = Input(shape=(6,), name=\"profile\")\n",
    "    #item features\n",
    "    item_input = Input(shape=(1,), name=\"item\")\n",
    "    item_category = Input(shape=(1,), name=\"category\")\n",
    "    \n",
    "    # User emb\n",
    "    click_history_emb = Embedding(output_dim=dims, \n",
    "                                  input_dim=num_items+1, \n",
    "                                  input_length=30, \n",
    "                                  embeddings_initializer='he_normal', \n",
    "                                  embeddings_regularizer=regularizers.l2(0.001),\n",
    "                                  name=\"mf_user_emb\")(user_history)\n",
    "    profile_emb = Embedding(output_dim=dims, \n",
    "                            input_dim=num_categories, \n",
    "                            input_length=6,\n",
    "                            embeddings_initializer='he_normal', \n",
    "                            embeddings_regularizer=regularizers.l2(0.001),\n",
    "                            name=\"mf_profile_emb\")(user_profile_input)\n",
    "    \n",
    "    # Item emb\n",
    "    item_emb = Embedding(output_dim=dims, \n",
    "                         input_dim=num_items+1, \n",
    "                         input_length=1,\n",
    "                         embeddings_initializer='he_normal', \n",
    "                         embeddings_regularizer=regularizers.l2(0.001),\n",
    "                         name=\"mf_item_emb\")(item_input)\n",
    "    category_emb = Embedding(output_dim=dims, \n",
    "                             input_dim=num_categories, \n",
    "                             input_length=1,\n",
    "                             embeddings_initializer='he_normal', \n",
    "                             embeddings_regularizer=regularizers.l2(0.001),\n",
    "                             name=\"cat_emb\")(item_category)\n",
    "    \n",
    "    \n",
    "    \n",
    "    lstm_tower_1 = profile_emb\n",
    "    lstm_tower_2 = click_history_emb\n",
    "    lstm_tower_1 = LSTM(40)(lstm_tower_1)\n",
    "    lstm_tower_1 = Dropout(0.8)(lstm_tower_1)\n",
    "    lstm_tower_1 = BatchNormalization(axis=1)(lstm_tower_1)\n",
    "    #lstm_vec = BatchNormalization(axis=1)(lstm_tower_1)\n",
    "    \n",
    "    lstm_tower_2 = LSTM(40)(lstm_tower_2)\n",
    "    lstm_tower_2 = Dropout(0.8)(lstm_tower_2)\n",
    "    lstm_tower_2 = BatchNormalization(axis=1)(lstm_tower_2)\n",
    "    lstm_vec = Concatenate(axis=1)([lstm_tower_1, lstm_tower_2])\n",
    "    \n",
    "    # MLP tower\n",
    "    item_vec = Flatten()(item_emb)\n",
    "    cat_vec = Flatten()(category_emb)\n",
    "    mlp_tower = Concatenate(axis=1)([item_vec,cat_vec])\n",
    "\n",
    "    mlp_tower = Dense(8)(mlp_tower)\n",
    "    mlp_tower = Dropout(0.5)(mlp_tower)\n",
    "    mlp_tower = BatchNormalization(axis=1)(mlp_tower)\n",
    "    \n",
    "    mlp_tower = Dense(2)(mlp_tower)\n",
    "    mlp_tower = Dropout(0.2)(mlp_tower)\n",
    "    mlp_tower = BatchNormalization(axis=1)(mlp_tower)\n",
    "    \n",
    "    \n",
    "    # Click predictor\n",
    "    final = Concatenate()([lstm_vec,mlp_tower ])\n",
    "    final = BatchNormalization(axis=1)(final)\n",
    "    y = Dense(1, activation=\"sigmoid\")(final)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[user_history, user_profile_input, item_input, item_category], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.01),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_arc6 = get_model_arc6(num_users, num_items, dims, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44100337",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training ########\n",
    "user_history = df_train.iloc[:, 10:].values.astype(\"int64\")\n",
    "profile_input = df_train.iloc[:, 1:7].values.astype(\"int64\")\n",
    "item_input = df_train.iloc[:, 7].values.reshape((-1,1)).astype(\"int64\")\n",
    "labels = df_train.iloc[:, 9].values.reshape((-1,1)).astype(\"int64\")\n",
    "category_input = df_train.iloc[:, 8].values.reshape((-1,1)).astype(\"int64\")\n",
    "print(user_history.shape,profile_input.shape, item_input.shape, labels.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = behaviors[\"user_id\"].unique()\n",
    "\n",
    "#user_input = df_train.iloc[:, 0].values.reshape((-1,1))\n",
    "#profile_input = df_train.iloc[:, 1:6].values\n",
    "#item_input = df_train.iloc[:, 7].values.reshape((-1,1))\n",
    "#labels = df_train.iloc[:, 8].values.reshape((-1,1))\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "hits_list = []\n",
    "ndcg_list = []\n",
    "best_hits = 0\n",
    "best_ndcgs = 0\n",
    "best_hits_five = 0\n",
    "best_ndcgs_five = 0\n",
    "\n",
    "epochs=6\n",
    "for epoch in range(epochs):\n",
    "    hist = model_arc6.fit([user_history, profile_input, item_input,category_input ], labels, epochs=1,validation_split=0.1, shuffle=True, verbose=1)    \n",
    "    train_loss.append(hist.history[\"loss\"])\n",
    "    train_acc.append(hist.history[\"accuracy\"])\n",
    "    val_loss.append(hist.history[\"val_loss\"])\n",
    "    val_acc.append(hist.history[\"val_accuracy\"])\n",
    "    \n",
    "    #hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc6( model_arc6, df_test, userid_to_true_item)\n",
    "    #hits_list.append(np.average(hits))\n",
    "    #ndcg_list.append(np.average(ndcgs))\n",
    "    \n",
    "    #temp_hits = np.average(hits)\n",
    "    #temp_ndcgs = np.average(ndcgs)\n",
    "    #if (temp_hits > best_hits):\n",
    "    #    best_hits = temp_hits\n",
    "    #    best_ndcgs = temp_ndcgs\n",
    "    #    best_hits_five = np.average(hits_five)\n",
    "    #    best_ndcgs_five = np.average(ndcgs_five)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9cf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, ndcgs, hits_five, ndcgs_five = evalaute_model_arc6( model_arc6, df_test, userid_to_true_item)\n",
    "print(np.average(hits))\n",
    "print(np.average(ndcgs))\n",
    "print(np.average(hits_five))\n",
    "print(np.average(ndcgs_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322eb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig(\"arc4_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94effd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(hits_list)\n",
    "plt.plot(train_loss)\n",
    "plt.title('Hit ratio vs Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Hit@10', 'Train loss'], loc='upper left')\n",
    "plt.savefig(\"arc4_hit_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_arc6(user_id, df, model):\n",
    "    \n",
    "    ## Setup ###\n",
    "    user_profile = get_user_profile(df, user_id)\n",
    "    click_history = userid_to_article_history[user_id]\n",
    "    display_items = df[df[\"user_id\"] == user_id][\"article_id\"].values.reshape(-1, 1).astype(\"int64\")\n",
    "    user_profile = np.tile(user_profile, display_items.shape[0]).reshape(-1, 6).astype(\"int64\")\n",
    "    category = get_item_features(user_id)\n",
    "    user_ids = np.tile(np.array(user_id), display_items.shape[0]).reshape(-1,1).astype(\"int64\")\n",
    "    category = np.asarray(category).astype(\"int64\")\n",
    "    click_history = np.tile(click_history, display_items.shape[0]).reshape(-1, 30).astype(\"int64\")\n",
    "\n",
    "    ## Preds ###\n",
    "    predictions = model.predict([click_history, user_profile, display_items, category])\n",
    "    predicted_labels = np.squeeze(predictions)\n",
    "    top_ten_items = [display_items[i][0] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    return top_ten_items\n",
    "\n",
    "def predict_all_users_arc6(df, model):\n",
    "    hits_ten,ndcgs_ten = [], []\n",
    "    hits_five, ndcgs_five = [], []\n",
    "\n",
    "    counter = 0\n",
    "    for user_id in tqdm(df[\"user_id\"].unique()[:800]):\n",
    "        top_ten_articles = get_recommendations_arc6(user_id, df,model)\n",
    "        top_ten_subcategories = [get_article_subcategory(_id, df) for _id in top_ten_articles]\n",
    "        user_profile = get_user_profile(df_test, user_id)\n",
    "\n",
    "        hit_ten = get_category_hit_ratio(user_profile, top_ten_subcategories)\n",
    "        ndcg_ten = get_ndcgs_category(user_profile, top_ten_subcategories)\n",
    "        \n",
    "        hit_five = get_category_hit_ratio(user_profile, top_ten_subcategories[:5])\n",
    "        ndcg_five = get_ndcgs_category(user_profile, top_ten_subcategories[:5])\n",
    "        \n",
    "        hits_ten.append(hit_ten)\n",
    "        ndcgs_ten.append(ndcg_ten)\n",
    "        hits_five.append(hit_five)\n",
    "        ndcgs_five.append(ndcg_five)\n",
    "        counter += 1\n",
    "    return np.average(hits_ten), np.average(ndcgs_ten), np.average(hits_five), np.average(ndcgs_five)\n",
    "        \n",
    "        \n",
    "category_hits_ten, category_ndcg_ten,category_hits_five,category_ndcg_five   = predict_all_users_arc6(df_test, model_arc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c3357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_hits_ten)\n",
    "print(category_ndcg_ten)\n",
    "print(category_hits_five)\n",
    "print(category_ndcg_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd00f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca50d586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d37331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ffbc58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
